{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uYW-Bo6G_uE",
        "outputId": "183b4b50-91f4-44b1-e68f-ba20e557344f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Selected Channels: 15 (Fp1, Fp2, F3, F4, Cz, P3, P4, C3, C4, Cz, P3, P4, Pz, O1, O2)\n",
        "- Range of Delta (for Artificial Data Generation): [0.0001, 0.0005]\n",
        "- Input size: (65, 198, 15)\n",
        "- Input type: Short Time Fourier Transform with window length 128, overlap 100\n",
        "- Number of samples: 1212 (1200 fake samples + 12 real samples)"
      ],
      "metadata": {
        "id": "3fWvMz6Me6Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "path = '/content/drive/My Drive/ML/'\n",
        "stft = np.load(path + 'Fstft3.npy')"
      ],
      "metadata": {
        "id": "F0mipD98HCfw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 4\n",
        "\n",
        "output_values = np.concatenate((np.tile(0, 303), np.tile(1, 303), np.tile(2, 303), np.tile(3, 303)))\n",
        "output_values = np.eye(num_classes)[output_values]\n",
        "\n",
        "data_array = stft"
      ],
      "metadata": {
        "id": "g2QMu4pLHGoi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1Y1xel9HJuN",
        "outputId": "0d7b84ce-5e1b-400d-9b18-e684f7bd3776"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1212, 15, 65, 198)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import zoom\n",
        "\n",
        "def resize_stft_matrix(stft_matrix, target_shape):\n",
        "    num_samples, num_channels, spec_rows, spec_cols = stft_matrix.shape\n",
        "\n",
        "    # Compute the scale factors for each dimension\n",
        "    scale_factors = (target_shape[0] / spec_rows, target_shape[1] / spec_cols)\n",
        "\n",
        "    # Perform bicubic interpolation to resize the STFT matrix\n",
        "    resized_stft_matrix = zoom(stft_matrix, (1, 1, *scale_factors), mode='reflect', order=3)\n",
        "\n",
        "    return resized_stft_matrix\n",
        "\n",
        "# Assuming 'stft_matrix' is the input STFT matrix of size (1200, 15, 65, 120)\n",
        "target_shape = (65, 65)\n",
        "\n",
        "resized_stft_matrix = resize_stft_matrix(data_array, target_shape)\n"
      ],
      "metadata": {
        "id": "zr_Mjcl8fWLV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_array = resized_stft_matrix\n",
        "data_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCwmvkcdhVAi",
        "outputId": "e4e79386-b7b9-485a-9921-35659125f188"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1212, 15, 65, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "uClYKYWoJpaV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "metadata": {
        "id": "TxBsjSrTwxsq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "train_params = {'dim': (65,65),\n",
        "                'batch_size': 64,\n",
        "                'n_classes':4,\n",
        "                'n_channels': 15,\n",
        "                'shuffle': True,\n",
        "                'input_type': 'stft',\n",
        "                'augment': True\n",
        "               }\n",
        "val_params = {'dim': (65,65),\n",
        "              'batch_size': 64,\n",
        "              'n_classes':4,\n",
        "              'n_channels': 15,\n",
        "              'shuffle': False,\n",
        "              'input_type': 'stft',\n",
        "              'augment': False\n",
        "             }"
      ],
      "metadata": {
        "id": "Suq5cIkUxHuu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "\n",
        "def mish(inputs):\n",
        "  x = tf.nn.softplus(inputs)\n",
        "  x = tf.nn.tanh(x)\n",
        "  x = tf.multiply(x, inputs)\n",
        "  return x\n",
        "\n",
        "\n",
        "stft_input = keras.Input(shape=(65, 65, 15))\n",
        "\n",
        "x = Conv2D(32, 3, activation=mish)(stft_input)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Conv2D(32, 5, strides=2, padding='same', activation=mish)(x)\n",
        "x  = Concatenate(axis=-1)([MaxPooling2D((1, 2))(x), AveragePooling2D((1, 2))(x)])\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "x = Conv2D(64, 5, strides=2, padding='same', activation=mish)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "x = Conv2D(128, 4, activation=mish)(x)\n",
        "x  = Concatenate(axis=-1)([MaxPooling2D((1, 2))(x), AveragePooling2D((1, 2))(x)])\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "stft_prediction = Dense(4, activation='softmax')(x)\n",
        "\n",
        "stft_model = Model(stft_input, stft_prediction)\n",
        "\n",
        "stft_model.compile(optimizer = 'adam',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=[\"accuracy\"])\n",
        "\n",
        "stft_model.summary()\n",
        "\n",
        "stft_annealer = LearningRateScheduler(lambda x: 1e-3 * 0.97 ** x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEgxh0_nxKvr",
        "outputId": "7795e18b-5248-420e-d9b0-32005d690635"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 65, 65, 15)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 63, 63, 32)   4352        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 63, 63, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 32)   25632       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 32, 16, 32)   0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 32, 16, 32)  0           ['conv2d_1[0][0]']               \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 16, 64)   0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 32, 16, 64)   0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 16, 8, 64)    102464      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 16, 8, 64)   256         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 16, 8, 64)    0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 13, 5, 128)   131200      ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 13, 2, 128)  0           ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 13, 2, 128)  0           ['conv2d_3[0][0]']               \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 13, 2, 256)   0           ['max_pooling2d_1[0][0]',        \n",
            "                                                                  'average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 13, 2, 256)  1024        ['concatenate_1[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 6656)         0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 6656)         0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 4)            26628       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 291,684\n",
            "Trainable params: 290,980\n",
            "Non-trainable params: 704\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_array.shape\n",
        "\n",
        "input = np.abs(np.transpose(data_array[:, :, :, :], (0, 2, 3, 1)))\n",
        "print(input.shape)\n",
        "\n",
        "X_train_temp, X_test, Y_train_temp, Y_test = train_test_split(input, output_values, test_size=0.3, random_state=42)\n",
        "X_train, X_validate, Y_train, Y_validate = train_test_split(X_train_temp, Y_train_temp, test_size=0.25, random_state=36)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh_eHtWux0R0",
        "outputId": "712cd1ca-7bd7-4abe-9a89-92ef5b6e791c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1212, 65, 65, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stft_history = stft_model.fit(X_train, Y_train, batch_size = 64, epochs = 300,\n",
        "                        verbose = 2, validation_data=(X_validate, Y_validate),\n",
        "                        callbacks=[stft_annealer], class_weight = {})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6slOiR_yCzo",
        "outputId": "ad07a498-89ba-4d97-eee9-f779aa2e748e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "10/10 - 20s - loss: 1.5213 - accuracy: 0.2579 - val_loss: 1.3863 - val_accuracy: 0.2453 - lr: 0.0010 - 20s/epoch - 2s/step\n",
            "Epoch 2/300\n",
            "10/10 - 15s - loss: 1.5092 - accuracy: 0.2406 - val_loss: 1.3867 - val_accuracy: 0.2453 - lr: 9.7000e-04 - 15s/epoch - 1s/step\n",
            "Epoch 3/300\n",
            "10/10 - 14s - loss: 1.4640 - accuracy: 0.2610 - val_loss: 1.3863 - val_accuracy: 0.2453 - lr: 9.4090e-04 - 14s/epoch - 1s/step\n",
            "Epoch 4/300\n",
            "10/10 - 14s - loss: 1.4440 - accuracy: 0.2830 - val_loss: 1.3860 - val_accuracy: 0.2689 - lr: 9.1267e-04 - 14s/epoch - 1s/step\n",
            "Epoch 5/300\n",
            "10/10 - 14s - loss: 1.4092 - accuracy: 0.3160 - val_loss: 1.3856 - val_accuracy: 0.2689 - lr: 8.8529e-04 - 14s/epoch - 1s/step\n",
            "Epoch 6/300\n",
            "10/10 - 14s - loss: 1.3274 - accuracy: 0.3506 - val_loss: 1.3867 - val_accuracy: 0.2689 - lr: 8.5873e-04 - 14s/epoch - 1s/step\n",
            "Epoch 7/300\n",
            "10/10 - 14s - loss: 1.2123 - accuracy: 0.4167 - val_loss: 1.3908 - val_accuracy: 0.2689 - lr: 8.3297e-04 - 14s/epoch - 1s/step\n",
            "Epoch 8/300\n",
            "10/10 - 14s - loss: 1.0874 - accuracy: 0.5063 - val_loss: 1.3956 - val_accuracy: 0.2689 - lr: 8.0798e-04 - 14s/epoch - 1s/step\n",
            "Epoch 9/300\n",
            "10/10 - 14s - loss: 1.0528 - accuracy: 0.5393 - val_loss: 1.4021 - val_accuracy: 0.2689 - lr: 7.8374e-04 - 14s/epoch - 1s/step\n",
            "Epoch 10/300\n",
            "10/10 - 14s - loss: 0.8603 - accuracy: 0.6038 - val_loss: 1.4128 - val_accuracy: 0.2689 - lr: 7.6023e-04 - 14s/epoch - 1s/step\n",
            "Epoch 11/300\n",
            "10/10 - 14s - loss: 0.7924 - accuracy: 0.6148 - val_loss: 1.4194 - val_accuracy: 0.2689 - lr: 7.3742e-04 - 14s/epoch - 1s/step\n",
            "Epoch 12/300\n",
            "10/10 - 13s - loss: 0.6885 - accuracy: 0.6777 - val_loss: 1.4472 - val_accuracy: 0.2453 - lr: 7.1530e-04 - 13s/epoch - 1s/step\n",
            "Epoch 13/300\n",
            "10/10 - 14s - loss: 0.6177 - accuracy: 0.6965 - val_loss: 1.4753 - val_accuracy: 0.2453 - lr: 6.9384e-04 - 14s/epoch - 1s/step\n",
            "Epoch 14/300\n",
            "10/10 - 14s - loss: 0.5124 - accuracy: 0.7579 - val_loss: 1.5806 - val_accuracy: 0.2453 - lr: 6.7303e-04 - 14s/epoch - 1s/step\n",
            "Epoch 15/300\n",
            "10/10 - 14s - loss: 0.4900 - accuracy: 0.7736 - val_loss: 1.7336 - val_accuracy: 0.2453 - lr: 6.5284e-04 - 14s/epoch - 1s/step\n",
            "Epoch 16/300\n",
            "10/10 - 13s - loss: 0.4136 - accuracy: 0.8113 - val_loss: 1.6917 - val_accuracy: 0.2453 - lr: 6.3325e-04 - 13s/epoch - 1s/step\n",
            "Epoch 17/300\n",
            "10/10 - 14s - loss: 0.3924 - accuracy: 0.8396 - val_loss: 1.9492 - val_accuracy: 0.2453 - lr: 6.1425e-04 - 14s/epoch - 1s/step\n",
            "Epoch 18/300\n",
            "10/10 - 14s - loss: 0.3850 - accuracy: 0.8381 - val_loss: 2.2969 - val_accuracy: 0.2453 - lr: 5.9583e-04 - 14s/epoch - 1s/step\n",
            "Epoch 19/300\n",
            "10/10 - 14s - loss: 0.3291 - accuracy: 0.8758 - val_loss: 3.0218 - val_accuracy: 0.2453 - lr: 5.7795e-04 - 14s/epoch - 1s/step\n",
            "Epoch 20/300\n",
            "10/10 - 13s - loss: 0.2536 - accuracy: 0.8947 - val_loss: 3.4758 - val_accuracy: 0.2453 - lr: 5.6061e-04 - 13s/epoch - 1s/step\n",
            "Epoch 21/300\n",
            "10/10 - 13s - loss: 0.2604 - accuracy: 0.8852 - val_loss: 4.5684 - val_accuracy: 0.2453 - lr: 5.4379e-04 - 13s/epoch - 1s/step\n",
            "Epoch 22/300\n",
            "10/10 - 14s - loss: 0.1900 - accuracy: 0.9198 - val_loss: 6.1974 - val_accuracy: 0.2453 - lr: 5.2748e-04 - 14s/epoch - 1s/step\n",
            "Epoch 23/300\n",
            "10/10 - 15s - loss: 0.1609 - accuracy: 0.9434 - val_loss: 6.9719 - val_accuracy: 0.2453 - lr: 5.1166e-04 - 15s/epoch - 2s/step\n",
            "Epoch 24/300\n",
            "10/10 - 16s - loss: 0.1904 - accuracy: 0.9324 - val_loss: 8.6624 - val_accuracy: 0.2453 - lr: 4.9631e-04 - 16s/epoch - 2s/step\n",
            "Epoch 25/300\n",
            "10/10 - 15s - loss: 0.1298 - accuracy: 0.9623 - val_loss: 8.9664 - val_accuracy: 0.2453 - lr: 4.8142e-04 - 15s/epoch - 2s/step\n",
            "Epoch 26/300\n",
            "10/10 - 16s - loss: 0.1432 - accuracy: 0.9434 - val_loss: 10.2037 - val_accuracy: 0.2453 - lr: 4.6697e-04 - 16s/epoch - 2s/step\n",
            "Epoch 27/300\n",
            "10/10 - 15s - loss: 0.0932 - accuracy: 0.9701 - val_loss: 11.4191 - val_accuracy: 0.2453 - lr: 4.5297e-04 - 15s/epoch - 1s/step\n",
            "Epoch 28/300\n",
            "10/10 - 15s - loss: 0.0954 - accuracy: 0.9686 - val_loss: 14.3399 - val_accuracy: 0.2453 - lr: 4.3938e-04 - 15s/epoch - 1s/step\n",
            "Epoch 29/300\n",
            "10/10 - 14s - loss: 0.0798 - accuracy: 0.9701 - val_loss: 17.0256 - val_accuracy: 0.2453 - lr: 4.2620e-04 - 14s/epoch - 1s/step\n",
            "Epoch 30/300\n",
            "10/10 - 14s - loss: 0.0707 - accuracy: 0.9748 - val_loss: 17.8601 - val_accuracy: 0.2453 - lr: 4.1341e-04 - 14s/epoch - 1s/step\n",
            "Epoch 31/300\n",
            "10/10 - 14s - loss: 0.0515 - accuracy: 0.9890 - val_loss: 21.3907 - val_accuracy: 0.2453 - lr: 4.0101e-04 - 14s/epoch - 1s/step\n",
            "Epoch 32/300\n",
            "10/10 - 14s - loss: 0.0460 - accuracy: 0.9921 - val_loss: 23.4810 - val_accuracy: 0.2453 - lr: 3.8898e-04 - 14s/epoch - 1s/step\n",
            "Epoch 33/300\n",
            "10/10 - 13s - loss: 0.0457 - accuracy: 0.9874 - val_loss: 25.9715 - val_accuracy: 0.2453 - lr: 3.7731e-04 - 13s/epoch - 1s/step\n",
            "Epoch 34/300\n",
            "10/10 - 14s - loss: 0.0350 - accuracy: 0.9953 - val_loss: 28.0215 - val_accuracy: 0.2453 - lr: 3.6599e-04 - 14s/epoch - 1s/step\n",
            "Epoch 35/300\n",
            "10/10 - 13s - loss: 0.0486 - accuracy: 0.9827 - val_loss: 29.3718 - val_accuracy: 0.2453 - lr: 3.5501e-04 - 13s/epoch - 1s/step\n",
            "Epoch 36/300\n",
            "10/10 - 14s - loss: 0.0408 - accuracy: 0.9843 - val_loss: 33.3664 - val_accuracy: 0.2453 - lr: 3.4436e-04 - 14s/epoch - 1s/step\n",
            "Epoch 37/300\n",
            "10/10 - 13s - loss: 0.0330 - accuracy: 0.9921 - val_loss: 33.1097 - val_accuracy: 0.2453 - lr: 3.3403e-04 - 13s/epoch - 1s/step\n",
            "Epoch 38/300\n",
            "10/10 - 14s - loss: 0.0286 - accuracy: 0.9953 - val_loss: 33.3477 - val_accuracy: 0.2453 - lr: 3.2401e-04 - 14s/epoch - 1s/step\n",
            "Epoch 39/300\n",
            "10/10 - 14s - loss: 0.0349 - accuracy: 0.9906 - val_loss: 34.8892 - val_accuracy: 0.2453 - lr: 3.1429e-04 - 14s/epoch - 1s/step\n",
            "Epoch 40/300\n",
            "10/10 - 15s - loss: 0.0200 - accuracy: 1.0000 - val_loss: 38.0363 - val_accuracy: 0.2453 - lr: 3.0486e-04 - 15s/epoch - 1s/step\n",
            "Epoch 41/300\n",
            "10/10 - 15s - loss: 0.0252 - accuracy: 0.9953 - val_loss: 39.5642 - val_accuracy: 0.2453 - lr: 2.9571e-04 - 15s/epoch - 2s/step\n",
            "Epoch 42/300\n",
            "10/10 - 17s - loss: 0.0297 - accuracy: 0.9969 - val_loss: 45.4424 - val_accuracy: 0.2453 - lr: 2.8684e-04 - 17s/epoch - 2s/step\n",
            "Epoch 43/300\n",
            "10/10 - 14s - loss: 0.0352 - accuracy: 0.9906 - val_loss: 48.1266 - val_accuracy: 0.2453 - lr: 2.7824e-04 - 14s/epoch - 1s/step\n",
            "Epoch 44/300\n",
            "10/10 - 15s - loss: 0.0230 - accuracy: 0.9953 - val_loss: 43.2271 - val_accuracy: 0.2453 - lr: 2.6989e-04 - 15s/epoch - 1s/step\n",
            "Epoch 45/300\n",
            "10/10 - 15s - loss: 0.0174 - accuracy: 0.9984 - val_loss: 51.2198 - val_accuracy: 0.2453 - lr: 2.6179e-04 - 15s/epoch - 1s/step\n",
            "Epoch 46/300\n",
            "10/10 - 16s - loss: 0.0257 - accuracy: 0.9921 - val_loss: 56.2955 - val_accuracy: 0.2453 - lr: 2.5394e-04 - 16s/epoch - 2s/step\n",
            "Epoch 47/300\n",
            "10/10 - 15s - loss: 0.0124 - accuracy: 1.0000 - val_loss: 60.7500 - val_accuracy: 0.2453 - lr: 2.4632e-04 - 15s/epoch - 2s/step\n",
            "Epoch 48/300\n",
            "10/10 - 14s - loss: 0.0093 - accuracy: 1.0000 - val_loss: 65.6912 - val_accuracy: 0.2453 - lr: 2.3893e-04 - 14s/epoch - 1s/step\n",
            "Epoch 49/300\n",
            "10/10 - 14s - loss: 0.0128 - accuracy: 0.9969 - val_loss: 66.9755 - val_accuracy: 0.2453 - lr: 2.3176e-04 - 14s/epoch - 1s/step\n",
            "Epoch 50/300\n",
            "10/10 - 15s - loss: 0.0083 - accuracy: 0.9984 - val_loss: 67.5695 - val_accuracy: 0.2453 - lr: 2.2481e-04 - 15s/epoch - 1s/step\n",
            "Epoch 51/300\n",
            "10/10 - 15s - loss: 0.0058 - accuracy: 1.0000 - val_loss: 68.9691 - val_accuracy: 0.2453 - lr: 2.1807e-04 - 15s/epoch - 1s/step\n",
            "Epoch 52/300\n",
            "10/10 - 14s - loss: 0.0143 - accuracy: 0.9969 - val_loss: 73.4067 - val_accuracy: 0.2453 - lr: 2.1152e-04 - 14s/epoch - 1s/step\n",
            "Epoch 53/300\n",
            "10/10 - 15s - loss: 0.0124 - accuracy: 0.9969 - val_loss: 83.2405 - val_accuracy: 0.2453 - lr: 2.0518e-04 - 15s/epoch - 1s/step\n",
            "Epoch 54/300\n",
            "10/10 - 17s - loss: 0.0150 - accuracy: 0.9969 - val_loss: 92.0303 - val_accuracy: 0.2453 - lr: 1.9902e-04 - 17s/epoch - 2s/step\n",
            "Epoch 55/300\n",
            "10/10 - 15s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 91.6503 - val_accuracy: 0.2453 - lr: 1.9305e-04 - 15s/epoch - 1s/step\n",
            "Epoch 56/300\n",
            "10/10 - 14s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 97.8971 - val_accuracy: 0.2453 - lr: 1.8726e-04 - 14s/epoch - 1s/step\n",
            "Epoch 57/300\n",
            "10/10 - 14s - loss: 0.0100 - accuracy: 1.0000 - val_loss: 108.1523 - val_accuracy: 0.2453 - lr: 1.8164e-04 - 14s/epoch - 1s/step\n",
            "Epoch 58/300\n",
            "10/10 - 14s - loss: 0.0089 - accuracy: 0.9984 - val_loss: 107.7378 - val_accuracy: 0.2453 - lr: 1.7619e-04 - 14s/epoch - 1s/step\n",
            "Epoch 59/300\n",
            "10/10 - 16s - loss: 0.0061 - accuracy: 1.0000 - val_loss: 108.2545 - val_accuracy: 0.2453 - lr: 1.7091e-04 - 16s/epoch - 2s/step\n",
            "Epoch 60/300\n",
            "10/10 - 15s - loss: 0.0074 - accuracy: 0.9984 - val_loss: 105.3362 - val_accuracy: 0.2453 - lr: 1.6578e-04 - 15s/epoch - 2s/step\n",
            "Epoch 61/300\n",
            "10/10 - 15s - loss: 0.0060 - accuracy: 0.9984 - val_loss: 103.4188 - val_accuracy: 0.2453 - lr: 1.6081e-04 - 15s/epoch - 1s/step\n",
            "Epoch 62/300\n",
            "10/10 - 15s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 101.2419 - val_accuracy: 0.2453 - lr: 1.5598e-04 - 15s/epoch - 1s/step\n",
            "Epoch 63/300\n",
            "10/10 - 15s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 102.1166 - val_accuracy: 0.2453 - lr: 1.5130e-04 - 15s/epoch - 1s/step\n",
            "Epoch 64/300\n",
            "10/10 - 14s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 110.2549 - val_accuracy: 0.2453 - lr: 1.4676e-04 - 14s/epoch - 1s/step\n",
            "Epoch 65/300\n",
            "10/10 - 14s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 120.9288 - val_accuracy: 0.2453 - lr: 1.4236e-04 - 14s/epoch - 1s/step\n",
            "Epoch 66/300\n",
            "10/10 - 14s - loss: 0.0066 - accuracy: 1.0000 - val_loss: 130.3305 - val_accuracy: 0.2453 - lr: 1.3809e-04 - 14s/epoch - 1s/step\n",
            "Epoch 67/300\n",
            "10/10 - 14s - loss: 0.0056 - accuracy: 1.0000 - val_loss: 120.4803 - val_accuracy: 0.2453 - lr: 1.3395e-04 - 14s/epoch - 1s/step\n",
            "Epoch 68/300\n",
            "10/10 - 14s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 117.5643 - val_accuracy: 0.2453 - lr: 1.2993e-04 - 14s/epoch - 1s/step\n",
            "Epoch 69/300\n",
            "10/10 - 14s - loss: 0.0047 - accuracy: 1.0000 - val_loss: 116.3025 - val_accuracy: 0.2453 - lr: 1.2603e-04 - 14s/epoch - 1s/step\n",
            "Epoch 70/300\n",
            "10/10 - 14s - loss: 0.0060 - accuracy: 1.0000 - val_loss: 120.1686 - val_accuracy: 0.2453 - lr: 1.2225e-04 - 14s/epoch - 1s/step\n",
            "Epoch 71/300\n",
            "10/10 - 14s - loss: 0.0073 - accuracy: 0.9984 - val_loss: 119.7661 - val_accuracy: 0.2453 - lr: 1.1858e-04 - 14s/epoch - 1s/step\n",
            "Epoch 72/300\n",
            "10/10 - 14s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 117.4863 - val_accuracy: 0.2453 - lr: 1.1503e-04 - 14s/epoch - 1s/step\n",
            "Epoch 73/300\n",
            "10/10 - 14s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 111.7224 - val_accuracy: 0.2453 - lr: 1.1157e-04 - 14s/epoch - 1s/step\n",
            "Epoch 74/300\n",
            "10/10 - 14s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 104.2715 - val_accuracy: 0.2453 - lr: 1.0823e-04 - 14s/epoch - 1s/step\n",
            "Epoch 75/300\n",
            "10/10 - 14s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 98.4961 - val_accuracy: 0.2453 - lr: 1.0498e-04 - 14s/epoch - 1s/step\n",
            "Epoch 76/300\n",
            "10/10 - 14s - loss: 0.0049 - accuracy: 1.0000 - val_loss: 91.3709 - val_accuracy: 0.2453 - lr: 1.0183e-04 - 14s/epoch - 1s/step\n",
            "Epoch 77/300\n",
            "10/10 - 14s - loss: 0.0049 - accuracy: 0.9984 - val_loss: 83.7394 - val_accuracy: 0.2453 - lr: 9.8776e-05 - 14s/epoch - 1s/step\n",
            "Epoch 78/300\n",
            "10/10 - 14s - loss: 0.0089 - accuracy: 0.9984 - val_loss: 80.4401 - val_accuracy: 0.2453 - lr: 9.5813e-05 - 14s/epoch - 1s/step\n",
            "Epoch 79/300\n",
            "10/10 - 15s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 71.4805 - val_accuracy: 0.2453 - lr: 9.2938e-05 - 15s/epoch - 1s/step\n",
            "Epoch 80/300\n",
            "10/10 - 14s - loss: 0.0061 - accuracy: 0.9984 - val_loss: 51.0328 - val_accuracy: 0.2453 - lr: 9.0150e-05 - 14s/epoch - 1s/step\n",
            "Epoch 81/300\n",
            "10/10 - 15s - loss: 0.0065 - accuracy: 0.9969 - val_loss: 40.3148 - val_accuracy: 0.2453 - lr: 8.7446e-05 - 15s/epoch - 1s/step\n",
            "Epoch 82/300\n",
            "10/10 - 14s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 22.2928 - val_accuracy: 0.2453 - lr: 8.4822e-05 - 14s/epoch - 1s/step\n",
            "Epoch 83/300\n",
            "10/10 - 15s - loss: 0.0049 - accuracy: 0.9984 - val_loss: 16.8132 - val_accuracy: 0.3915 - lr: 8.2278e-05 - 15s/epoch - 1s/step\n",
            "Epoch 84/300\n",
            "10/10 - 16s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 22.9529 - val_accuracy: 0.2453 - lr: 7.9809e-05 - 16s/epoch - 2s/step\n",
            "Epoch 85/300\n",
            "10/10 - 14s - loss: 0.0067 - accuracy: 1.0000 - val_loss: 24.2785 - val_accuracy: 0.2453 - lr: 7.7415e-05 - 14s/epoch - 1s/step\n",
            "Epoch 86/300\n",
            "10/10 - 14s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 22.2364 - val_accuracy: 0.3915 - lr: 7.5093e-05 - 14s/epoch - 1s/step\n",
            "Epoch 87/300\n",
            "10/10 - 15s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 15.7318 - val_accuracy: 0.3915 - lr: 7.2840e-05 - 15s/epoch - 2s/step\n",
            "Epoch 88/300\n",
            "10/10 - 14s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 10.4094 - val_accuracy: 0.4906 - lr: 7.0655e-05 - 14s/epoch - 1s/step\n",
            "Epoch 89/300\n",
            "10/10 - 14s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 8.1432 - val_accuracy: 0.4906 - lr: 6.8535e-05 - 14s/epoch - 1s/step\n",
            "Epoch 90/300\n",
            "10/10 - 14s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.7314 - val_accuracy: 0.4009 - lr: 6.6479e-05 - 14s/epoch - 1s/step\n",
            "Epoch 91/300\n",
            "10/10 - 14s - loss: 0.0119 - accuracy: 0.9969 - val_loss: 5.6519 - val_accuracy: 0.4009 - lr: 6.4485e-05 - 14s/epoch - 1s/step\n",
            "Epoch 92/300\n",
            "10/10 - 15s - loss: 0.0107 - accuracy: 0.9969 - val_loss: 8.7502 - val_accuracy: 0.4906 - lr: 6.2550e-05 - 15s/epoch - 1s/step\n",
            "Epoch 93/300\n",
            "10/10 - 14s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 7.9427 - val_accuracy: 0.5849 - lr: 6.0674e-05 - 14s/epoch - 1s/step\n",
            "Epoch 94/300\n",
            "10/10 - 14s - loss: 0.0139 - accuracy: 0.9969 - val_loss: 7.1249 - val_accuracy: 0.5849 - lr: 5.8853e-05 - 14s/epoch - 1s/step\n",
            "Epoch 95/300\n",
            "10/10 - 14s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 5.3649 - val_accuracy: 0.5849 - lr: 5.7088e-05 - 14s/epoch - 1s/step\n",
            "Epoch 96/300\n",
            "10/10 - 14s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.9837 - val_accuracy: 0.6698 - lr: 5.5375e-05 - 14s/epoch - 1s/step\n",
            "Epoch 97/300\n",
            "10/10 - 14s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.8302 - lr: 5.3714e-05 - 14s/epoch - 1s/step\n",
            "Epoch 98/300\n",
            "10/10 - 15s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5897 - val_accuracy: 0.9151 - lr: 5.2102e-05 - 15s/epoch - 2s/step\n",
            "Epoch 99/300\n",
            "10/10 - 15s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.8302 - lr: 5.0539e-05 - 15s/epoch - 1s/step\n",
            "Epoch 100/300\n",
            "10/10 - 16s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.8128 - val_accuracy: 0.8302 - lr: 4.9023e-05 - 16s/epoch - 2s/step\n",
            "Epoch 101/300\n",
            "10/10 - 15s - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.6491 - val_accuracy: 0.8302 - lr: 4.7553e-05 - 15s/epoch - 1s/step\n",
            "Epoch 102/300\n",
            "10/10 - 15s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5697 - val_accuracy: 0.8302 - lr: 4.6126e-05 - 15s/epoch - 1s/step\n",
            "Epoch 103/300\n",
            "10/10 - 14s - loss: 0.0089 - accuracy: 0.9984 - val_loss: 1.8812 - val_accuracy: 0.6698 - lr: 4.4742e-05 - 14s/epoch - 1s/step\n",
            "Epoch 104/300\n",
            "10/10 - 14s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.7967 - val_accuracy: 0.6698 - lr: 4.3400e-05 - 14s/epoch - 1s/step\n",
            "Epoch 105/300\n",
            "10/10 - 14s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.1071 - val_accuracy: 0.6698 - lr: 4.2098e-05 - 14s/epoch - 1s/step\n",
            "Epoch 106/300\n",
            "10/10 - 14s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.1082 - val_accuracy: 0.6698 - lr: 4.0835e-05 - 14s/epoch - 1s/step\n",
            "Epoch 107/300\n",
            "10/10 - 14s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.4578 - val_accuracy: 0.6698 - lr: 3.9610e-05 - 14s/epoch - 1s/step\n",
            "Epoch 108/300\n",
            "10/10 - 15s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.3722 - val_accuracy: 0.6934 - lr: 3.8422e-05 - 15s/epoch - 1s/step\n",
            "Epoch 109/300\n",
            "10/10 - 15s - loss: 0.0047 - accuracy: 0.9984 - val_loss: 4.0324 - val_accuracy: 0.7547 - lr: 3.7269e-05 - 15s/epoch - 1s/step\n",
            "Epoch 110/300\n",
            "10/10 - 14s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.8650 - val_accuracy: 0.7547 - lr: 3.6151e-05 - 14s/epoch - 1s/step\n",
            "Epoch 111/300\n",
            "10/10 - 14s - loss: 0.0061 - accuracy: 0.9984 - val_loss: 4.4136 - val_accuracy: 0.7547 - lr: 3.5066e-05 - 14s/epoch - 1s/step\n",
            "Epoch 112/300\n",
            "10/10 - 14s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.2274 - val_accuracy: 0.7547 - lr: 3.4014e-05 - 14s/epoch - 1s/step\n",
            "Epoch 113/300\n",
            "10/10 - 14s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 5.1373 - val_accuracy: 0.7547 - lr: 3.2994e-05 - 14s/epoch - 1s/step\n",
            "Epoch 114/300\n",
            "10/10 - 14s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.5260 - val_accuracy: 0.7547 - lr: 3.2004e-05 - 14s/epoch - 1s/step\n",
            "Epoch 115/300\n",
            "10/10 - 13s - loss: 0.0040 - accuracy: 0.9984 - val_loss: 3.7035 - val_accuracy: 0.7547 - lr: 3.1044e-05 - 13s/epoch - 1s/step\n",
            "Epoch 116/300\n",
            "10/10 - 13s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.8073 - val_accuracy: 0.7547 - lr: 3.0113e-05 - 13s/epoch - 1s/step\n",
            "Epoch 117/300\n",
            "10/10 - 14s - loss: 0.0057 - accuracy: 0.9984 - val_loss: 4.2346 - val_accuracy: 0.7547 - lr: 2.9209e-05 - 14s/epoch - 1s/step\n",
            "Epoch 118/300\n",
            "10/10 - 13s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.9342 - val_accuracy: 0.7547 - lr: 2.8333e-05 - 13s/epoch - 1s/step\n",
            "Epoch 119/300\n",
            "10/10 - 14s - loss: 0.0117 - accuracy: 0.9984 - val_loss: 1.5430 - val_accuracy: 0.7547 - lr: 2.7483e-05 - 14s/epoch - 1s/step\n",
            "Epoch 120/300\n",
            "10/10 - 14s - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.0206 - val_accuracy: 1.0000 - lr: 2.6659e-05 - 14s/epoch - 1s/step\n",
            "Epoch 121/300\n",
            "10/10 - 14s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 1.0000 - lr: 2.5859e-05 - 14s/epoch - 1s/step\n",
            "Epoch 122/300\n",
            "10/10 - 14s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000 - lr: 2.5083e-05 - 14s/epoch - 1s/step\n",
            "Epoch 123/300\n",
            "10/10 - 15s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000 - lr: 2.4331e-05 - 15s/epoch - 1s/step\n",
            "Epoch 124/300\n",
            "10/10 - 15s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 1.0000 - lr: 2.3601e-05 - 15s/epoch - 1s/step\n",
            "Epoch 125/300\n",
            "10/10 - 14s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000 - lr: 2.2893e-05 - 14s/epoch - 1s/step\n",
            "Epoch 126/300\n",
            "10/10 - 15s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9151 - lr: 2.2206e-05 - 15s/epoch - 1s/step\n",
            "Epoch 127/300\n",
            "10/10 - 15s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.7311 - lr: 2.1540e-05 - 15s/epoch - 2s/step\n",
            "Epoch 128/300\n",
            "10/10 - 15s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 1.0000 - lr: 2.0893e-05 - 15s/epoch - 2s/step\n",
            "Epoch 129/300\n",
            "10/10 - 14s - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.0240 - val_accuracy: 1.0000 - lr: 2.0267e-05 - 14s/epoch - 1s/step\n",
            "Epoch 130/300\n",
            "10/10 - 14s - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.1627 - val_accuracy: 0.9151 - lr: 1.9659e-05 - 14s/epoch - 1s/step\n",
            "Epoch 131/300\n",
            "10/10 - 14s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.7311 - lr: 1.9069e-05 - 14s/epoch - 1s/step\n",
            "Epoch 132/300\n",
            "10/10 - 14s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8305 - val_accuracy: 0.7311 - lr: 1.8497e-05 - 14s/epoch - 1s/step\n",
            "Epoch 133/300\n",
            "10/10 - 14s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1348 - val_accuracy: 0.7311 - lr: 1.7942e-05 - 14s/epoch - 1s/step\n",
            "Epoch 134/300\n",
            "10/10 - 14s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.7311 - lr: 1.7404e-05 - 14s/epoch - 1s/step\n",
            "Epoch 135/300\n",
            "10/10 - 14s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.3491 - val_accuracy: 0.7311 - lr: 1.6882e-05 - 14s/epoch - 1s/step\n",
            "Epoch 136/300\n",
            "10/10 - 14s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0491 - val_accuracy: 0.6462 - lr: 1.6375e-05 - 14s/epoch - 1s/step\n",
            "Epoch 137/300\n",
            "10/10 - 14s - loss: 0.0061 - accuracy: 0.9969 - val_loss: 2.0386 - val_accuracy: 0.6462 - lr: 1.5884e-05 - 14s/epoch - 1s/step\n",
            "Epoch 138/300\n",
            "10/10 - 14s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8565 - val_accuracy: 0.7311 - lr: 1.5407e-05 - 14s/epoch - 1s/step\n",
            "Epoch 139/300\n",
            "10/10 - 14s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6397 - val_accuracy: 0.7311 - lr: 1.4945e-05 - 14s/epoch - 1s/step\n",
            "Epoch 140/300\n",
            "10/10 - 15s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9993 - val_accuracy: 0.7311 - lr: 1.4497e-05 - 15s/epoch - 1s/step\n",
            "Epoch 141/300\n",
            "10/10 - 16s - loss: 0.0031 - accuracy: 0.9984 - val_loss: 0.5582 - val_accuracy: 0.7311 - lr: 1.4062e-05 - 16s/epoch - 2s/step\n",
            "Epoch 142/300\n",
            "10/10 - 15s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9151 - lr: 1.3640e-05 - 15s/epoch - 2s/step\n",
            "Epoch 143/300\n",
            "10/10 - 15s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9151 - lr: 1.3231e-05 - 15s/epoch - 1s/step\n",
            "Epoch 144/300\n",
            "10/10 - 15s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.7311 - lr: 1.2834e-05 - 15s/epoch - 1s/step\n",
            "Epoch 145/300\n",
            "10/10 - 15s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4618 - val_accuracy: 0.7311 - lr: 1.2449e-05 - 15s/epoch - 1s/step\n",
            "Epoch 146/300\n",
            "10/10 - 14s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9151 - lr: 1.2075e-05 - 14s/epoch - 1s/step\n",
            "Epoch 147/300\n",
            "10/10 - 14s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9717 - lr: 1.1713e-05 - 14s/epoch - 1s/step\n",
            "Epoch 148/300\n",
            "10/10 - 14s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 1.0000 - lr: 1.1362e-05 - 14s/epoch - 1s/step\n",
            "Epoch 149/300\n",
            "10/10 - 14s - loss: 0.0047 - accuracy: 0.9969 - val_loss: 0.0017 - val_accuracy: 1.0000 - lr: 1.1021e-05 - 14s/epoch - 1s/step\n",
            "Epoch 150/300\n",
            "10/10 - 14s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 5.6394e-04 - val_accuracy: 1.0000 - lr: 1.0690e-05 - 14s/epoch - 1s/step\n",
            "Epoch 151/300\n",
            "10/10 - 14s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 1.0370e-05 - 14s/epoch - 1s/step\n",
            "Epoch 152/300\n",
            "10/10 - 14s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000 - lr: 1.0058e-05 - 14s/epoch - 1s/step\n",
            "Epoch 153/300\n",
            "10/10 - 14s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000 - lr: 9.7567e-06 - 14s/epoch - 1s/step\n",
            "Epoch 154/300\n",
            "10/10 - 14s - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0068 - val_accuracy: 1.0000 - lr: 9.4640e-06 - 14s/epoch - 1s/step\n",
            "Epoch 155/300\n",
            "10/10 - 14s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000 - lr: 9.1801e-06 - 14s/epoch - 1s/step\n",
            "Epoch 156/300\n",
            "10/10 - 14s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000 - lr: 8.9047e-06 - 14s/epoch - 1s/step\n",
            "Epoch 157/300\n",
            "10/10 - 14s - loss: 0.0059 - accuracy: 0.9984 - val_loss: 4.2824e-04 - val_accuracy: 1.0000 - lr: 8.6375e-06 - 14s/epoch - 1s/step\n",
            "Epoch 158/300\n",
            "10/10 - 14s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.8688e-04 - val_accuracy: 1.0000 - lr: 8.3784e-06 - 14s/epoch - 1s/step\n",
            "Epoch 159/300\n",
            "10/10 - 14s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.5931e-04 - val_accuracy: 1.0000 - lr: 8.1271e-06 - 14s/epoch - 1s/step\n",
            "Epoch 160/300\n",
            "10/10 - 14s - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.0012 - val_accuracy: 1.0000 - lr: 7.8833e-06 - 14s/epoch - 1s/step\n",
            "Epoch 161/300\n",
            "10/10 - 14s - loss: 0.0035 - accuracy: 0.9984 - val_loss: 2.9008e-04 - val_accuracy: 1.0000 - lr: 7.6468e-06 - 14s/epoch - 1s/step\n",
            "Epoch 162/300\n",
            "10/10 - 14s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.5683e-04 - val_accuracy: 1.0000 - lr: 7.4174e-06 - 14s/epoch - 1s/step\n",
            "Epoch 163/300\n",
            "10/10 - 14s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000 - lr: 7.1948e-06 - 14s/epoch - 1s/step\n",
            "Epoch 164/300\n",
            "10/10 - 14s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000 - lr: 6.9790e-06 - 14s/epoch - 1s/step\n",
            "Epoch 165/300\n",
            "10/10 - 14s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000 - lr: 6.7696e-06 - 14s/epoch - 1s/step\n",
            "Epoch 166/300\n",
            "10/10 - 14s - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.0281 - val_accuracy: 1.0000 - lr: 6.5665e-06 - 14s/epoch - 1s/step\n",
            "Epoch 167/300\n",
            "10/10 - 14s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9906 - lr: 6.3695e-06 - 14s/epoch - 1s/step\n",
            "Epoch 168/300\n",
            "10/10 - 14s - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.1670 - val_accuracy: 0.9151 - lr: 6.1785e-06 - 14s/epoch - 1s/step\n",
            "Epoch 169/300\n",
            "10/10 - 14s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.8019 - lr: 5.9931e-06 - 14s/epoch - 1s/step\n",
            "Epoch 170/300\n",
            "10/10 - 14s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.7689 - lr: 5.8133e-06 - 14s/epoch - 1s/step\n",
            "Epoch 171/300\n",
            "10/10 - 14s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.7453 - lr: 5.6389e-06 - 14s/epoch - 1s/step\n",
            "Epoch 172/300\n",
            "10/10 - 14s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9151 - lr: 5.4697e-06 - 14s/epoch - 1s/step\n",
            "Epoch 173/300\n",
            "10/10 - 14s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9151 - lr: 5.3056e-06 - 14s/epoch - 1s/step\n",
            "Epoch 174/300\n",
            "10/10 - 14s - loss: 0.0041 - accuracy: 0.9984 - val_loss: 0.0296 - val_accuracy: 1.0000 - lr: 5.1465e-06 - 14s/epoch - 1s/step\n",
            "Epoch 175/300\n",
            "10/10 - 14s - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.0035 - val_accuracy: 1.0000 - lr: 4.9921e-06 - 14s/epoch - 1s/step\n",
            "Epoch 176/300\n",
            "10/10 - 14s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 8.6823e-04 - val_accuracy: 1.0000 - lr: 4.8423e-06 - 14s/epoch - 1s/step\n",
            "Epoch 177/300\n",
            "10/10 - 15s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 6.2867e-04 - val_accuracy: 1.0000 - lr: 4.6971e-06 - 15s/epoch - 1s/step\n",
            "Epoch 178/300\n",
            "10/10 - 15s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - lr: 4.5561e-06 - 15s/epoch - 1s/step\n",
            "Epoch 179/300\n",
            "10/10 - 14s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 9.1285e-04 - val_accuracy: 1.0000 - lr: 4.4195e-06 - 14s/epoch - 1s/step\n",
            "Epoch 180/300\n",
            "10/10 - 14s - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0052 - val_accuracy: 1.0000 - lr: 4.2869e-06 - 14s/epoch - 1s/step\n",
            "Epoch 181/300\n",
            "10/10 - 14s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 1.0000 - lr: 4.1583e-06 - 14s/epoch - 1s/step\n",
            "Epoch 182/300\n",
            "10/10 - 15s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9623 - lr: 4.0335e-06 - 15s/epoch - 1s/step\n",
            "Epoch 183/300\n",
            "10/10 - 14s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9717 - lr: 3.9125e-06 - 14s/epoch - 1s/step\n",
            "Epoch 184/300\n",
            "10/10 - 14s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 1.0000 - lr: 3.7951e-06 - 14s/epoch - 1s/step\n",
            "Epoch 185/300\n",
            "10/10 - 14s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000 - lr: 3.6813e-06 - 14s/epoch - 1s/step\n",
            "Epoch 186/300\n",
            "10/10 - 15s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000 - lr: 3.5708e-06 - 15s/epoch - 1s/step\n",
            "Epoch 187/300\n",
            "10/10 - 14s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - lr: 3.4637e-06 - 14s/epoch - 1s/step\n",
            "Epoch 188/300\n",
            "10/10 - 15s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.6373e-04 - val_accuracy: 1.0000 - lr: 3.3598e-06 - 15s/epoch - 1s/step\n",
            "Epoch 189/300\n",
            "10/10 - 14s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.5477e-04 - val_accuracy: 1.0000 - lr: 3.2590e-06 - 14s/epoch - 1s/step\n",
            "Epoch 190/300\n",
            "10/10 - 14s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.0960e-04 - val_accuracy: 1.0000 - lr: 3.1612e-06 - 14s/epoch - 1s/step\n",
            "Epoch 191/300\n",
            "10/10 - 14s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 5.3501e-04 - val_accuracy: 1.0000 - lr: 3.0664e-06 - 14s/epoch - 1s/step\n",
            "Epoch 192/300\n",
            "10/10 - 15s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000 - lr: 2.9744e-06 - 15s/epoch - 1s/step\n",
            "Epoch 193/300\n",
            "10/10 - 15s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000 - lr: 2.8852e-06 - 15s/epoch - 1s/step\n",
            "Epoch 194/300\n",
            "10/10 - 14s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 2.7986e-06 - 14s/epoch - 1s/step\n",
            "Epoch 195/300\n",
            "10/10 - 15s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 5.4842e-04 - val_accuracy: 1.0000 - lr: 2.7147e-06 - 15s/epoch - 2s/step\n",
            "Epoch 196/300\n",
            "10/10 - 14s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.1924e-04 - val_accuracy: 1.0000 - lr: 2.6332e-06 - 14s/epoch - 1s/step\n",
            "Epoch 197/300\n",
            "10/10 - 14s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.6672e-04 - val_accuracy: 1.0000 - lr: 2.5542e-06 - 14s/epoch - 1s/step\n",
            "Epoch 198/300\n",
            "10/10 - 15s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.3999e-04 - val_accuracy: 1.0000 - lr: 2.4776e-06 - 15s/epoch - 1s/step\n",
            "Epoch 199/300\n",
            "10/10 - 14s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.0512e-04 - val_accuracy: 1.0000 - lr: 2.4033e-06 - 14s/epoch - 1s/step\n",
            "Epoch 200/300\n",
            "10/10 - 14s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.9199e-04 - val_accuracy: 1.0000 - lr: 2.3312e-06 - 14s/epoch - 1s/step\n",
            "Epoch 201/300\n",
            "10/10 - 15s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8134e-04 - val_accuracy: 1.0000 - lr: 2.2612e-06 - 15s/epoch - 2s/step\n",
            "Epoch 202/300\n",
            "10/10 - 14s - loss: 0.0045 - accuracy: 0.9984 - val_loss: 1.8803e-04 - val_accuracy: 1.0000 - lr: 2.1934e-06 - 14s/epoch - 1s/step\n",
            "Epoch 203/300\n",
            "10/10 - 14s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9251e-04 - val_accuracy: 1.0000 - lr: 2.1276e-06 - 14s/epoch - 1s/step\n",
            "Epoch 204/300\n",
            "10/10 - 15s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9937e-04 - val_accuracy: 1.0000 - lr: 2.0638e-06 - 15s/epoch - 1s/step\n",
            "Epoch 205/300\n",
            "10/10 - 15s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.1969e-04 - val_accuracy: 1.0000 - lr: 2.0019e-06 - 15s/epoch - 1s/step\n",
            "Epoch 206/300\n",
            "10/10 - 14s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4132e-04 - val_accuracy: 1.0000 - lr: 1.9418e-06 - 14s/epoch - 1s/step\n",
            "Epoch 207/300\n",
            "10/10 - 14s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.2615e-04 - val_accuracy: 1.0000 - lr: 1.8836e-06 - 14s/epoch - 1s/step\n",
            "Epoch 208/300\n",
            "10/10 - 15s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2848e-04 - val_accuracy: 1.0000 - lr: 1.8270e-06 - 15s/epoch - 1s/step\n",
            "Epoch 209/300\n",
            "10/10 - 14s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.0128e-04 - val_accuracy: 1.0000 - lr: 1.7722e-06 - 14s/epoch - 1s/step\n",
            "Epoch 210/300\n",
            "10/10 - 14s - loss: 0.0048 - accuracy: 0.9984 - val_loss: 1.8479e-04 - val_accuracy: 1.0000 - lr: 1.7191e-06 - 14s/epoch - 1s/step\n",
            "Epoch 211/300\n",
            "10/10 - 14s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.8491e-04 - val_accuracy: 1.0000 - lr: 1.6675e-06 - 14s/epoch - 1s/step\n",
            "Epoch 212/300\n",
            "10/10 - 14s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9705e-04 - val_accuracy: 1.0000 - lr: 1.6175e-06 - 14s/epoch - 1s/step\n",
            "Epoch 213/300\n",
            "10/10 - 15s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.2108e-04 - val_accuracy: 1.0000 - lr: 1.5689e-06 - 15s/epoch - 1s/step\n",
            "Epoch 214/300\n",
            "10/10 - 14s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.7118e-04 - val_accuracy: 1.0000 - lr: 1.5219e-06 - 14s/epoch - 1s/step\n",
            "Epoch 215/300\n",
            "10/10 - 14s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.0719e-04 - val_accuracy: 1.0000 - lr: 1.4762e-06 - 14s/epoch - 1s/step\n",
            "Epoch 216/300\n",
            "10/10 - 15s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.0340e-04 - val_accuracy: 1.0000 - lr: 1.4319e-06 - 15s/epoch - 1s/step\n",
            "Epoch 217/300\n",
            "10/10 - 14s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.6337e-04 - val_accuracy: 1.0000 - lr: 1.3890e-06 - 14s/epoch - 1s/step\n",
            "Epoch 218/300\n",
            "10/10 - 15s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.4693e-04 - val_accuracy: 1.0000 - lr: 1.3473e-06 - 15s/epoch - 1s/step\n",
            "Epoch 219/300\n",
            "10/10 - 15s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.3981e-04 - val_accuracy: 1.0000 - lr: 1.3069e-06 - 15s/epoch - 1s/step\n",
            "Epoch 220/300\n",
            "10/10 - 14s - loss: 0.0059 - accuracy: 0.9984 - val_loss: 2.2345e-04 - val_accuracy: 1.0000 - lr: 1.2677e-06 - 14s/epoch - 1s/step\n",
            "Epoch 221/300\n",
            "10/10 - 14s - loss: 0.0036 - accuracy: 0.9984 - val_loss: 2.1669e-04 - val_accuracy: 1.0000 - lr: 1.2297e-06 - 14s/epoch - 1s/step\n",
            "Epoch 222/300\n",
            "10/10 - 14s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.2207e-04 - val_accuracy: 1.0000 - lr: 1.1928e-06 - 14s/epoch - 1s/step\n",
            "Epoch 223/300\n",
            "10/10 - 14s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1857e-04 - val_accuracy: 1.0000 - lr: 1.1570e-06 - 14s/epoch - 1s/step\n",
            "Epoch 224/300\n",
            "10/10 - 15s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.3231e-04 - val_accuracy: 1.0000 - lr: 1.1223e-06 - 15s/epoch - 1s/step\n",
            "Epoch 225/300\n",
            "10/10 - 18s - loss: 0.0032 - accuracy: 0.9984 - val_loss: 2.2013e-04 - val_accuracy: 1.0000 - lr: 1.0886e-06 - 18s/epoch - 2s/step\n",
            "Epoch 226/300\n",
            "10/10 - 16s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.9843e-04 - val_accuracy: 1.0000 - lr: 1.0559e-06 - 16s/epoch - 2s/step\n",
            "Epoch 227/300\n",
            "10/10 - 15s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.7872e-04 - val_accuracy: 1.0000 - lr: 1.0243e-06 - 15s/epoch - 2s/step\n",
            "Epoch 228/300\n",
            "10/10 - 15s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8306e-04 - val_accuracy: 1.0000 - lr: 9.9354e-07 - 15s/epoch - 1s/step\n",
            "Epoch 229/300\n",
            "10/10 - 16s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.9438e-04 - val_accuracy: 1.0000 - lr: 9.6373e-07 - 16s/epoch - 2s/step\n",
            "Epoch 230/300\n",
            "10/10 - 15s - loss: 0.0051 - accuracy: 0.9984 - val_loss: 2.0228e-04 - val_accuracy: 1.0000 - lr: 9.3482e-07 - 15s/epoch - 2s/step\n",
            "Epoch 231/300\n",
            "10/10 - 15s - loss: 0.0056 - accuracy: 0.9969 - val_loss: 1.8860e-04 - val_accuracy: 1.0000 - lr: 9.0677e-07 - 15s/epoch - 1s/step\n",
            "Epoch 232/300\n",
            "10/10 - 15s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.1190e-04 - val_accuracy: 1.0000 - lr: 8.7957e-07 - 15s/epoch - 2s/step\n",
            "Epoch 233/300\n",
            "10/10 - 15s - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.3256e-04 - val_accuracy: 1.0000 - lr: 8.5318e-07 - 15s/epoch - 1s/step\n",
            "Epoch 234/300\n",
            "10/10 - 15s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.4517e-04 - val_accuracy: 1.0000 - lr: 8.2759e-07 - 15s/epoch - 1s/step\n",
            "Epoch 235/300\n",
            "10/10 - 14s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.6332e-04 - val_accuracy: 1.0000 - lr: 8.0276e-07 - 14s/epoch - 1s/step\n",
            "Epoch 236/300\n",
            "10/10 - 14s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.3656e-04 - val_accuracy: 1.0000 - lr: 7.7868e-07 - 14s/epoch - 1s/step\n",
            "Epoch 237/300\n",
            "10/10 - 14s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.1518e-04 - val_accuracy: 1.0000 - lr: 7.5532e-07 - 14s/epoch - 1s/step\n",
            "Epoch 238/300\n",
            "10/10 - 14s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.6457e-04 - val_accuracy: 1.0000 - lr: 7.3266e-07 - 14s/epoch - 1s/step\n",
            "Epoch 239/300\n",
            "10/10 - 14s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.5464e-04 - val_accuracy: 1.0000 - lr: 7.1068e-07 - 14s/epoch - 1s/step\n",
            "Epoch 240/300\n",
            "10/10 - 14s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0536e-04 - val_accuracy: 1.0000 - lr: 6.8936e-07 - 14s/epoch - 1s/step\n",
            "Epoch 241/300\n",
            "10/10 - 14s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.6645e-04 - val_accuracy: 1.0000 - lr: 6.6868e-07 - 14s/epoch - 1s/step\n",
            "Epoch 242/300\n",
            "10/10 - 14s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.5586e-04 - val_accuracy: 1.0000 - lr: 6.4862e-07 - 14s/epoch - 1s/step\n",
            "Epoch 243/300\n",
            "10/10 - 14s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3432e-04 - val_accuracy: 1.0000 - lr: 6.2916e-07 - 14s/epoch - 1s/step\n",
            "Epoch 244/300\n",
            "10/10 - 14s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1083e-04 - val_accuracy: 1.0000 - lr: 6.1028e-07 - 14s/epoch - 1s/step\n",
            "Epoch 245/300\n",
            "10/10 - 14s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9320e-04 - val_accuracy: 1.0000 - lr: 5.9197e-07 - 14s/epoch - 1s/step\n",
            "Epoch 246/300\n",
            "10/10 - 14s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.7998e-04 - val_accuracy: 1.0000 - lr: 5.7422e-07 - 14s/epoch - 1s/step\n",
            "Epoch 247/300\n",
            "10/10 - 14s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7301e-04 - val_accuracy: 1.0000 - lr: 5.5699e-07 - 14s/epoch - 1s/step\n",
            "Epoch 248/300\n",
            "10/10 - 14s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7231e-04 - val_accuracy: 1.0000 - lr: 5.4028e-07 - 14s/epoch - 1s/step\n",
            "Epoch 249/300\n",
            "10/10 - 14s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7158e-04 - val_accuracy: 1.0000 - lr: 5.2407e-07 - 14s/epoch - 1s/step\n",
            "Epoch 250/300\n",
            "10/10 - 14s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7297e-04 - val_accuracy: 1.0000 - lr: 5.0835e-07 - 14s/epoch - 1s/step\n",
            "Epoch 251/300\n",
            "10/10 - 14s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7464e-04 - val_accuracy: 1.0000 - lr: 4.9310e-07 - 14s/epoch - 1s/step\n",
            "Epoch 252/300\n",
            "10/10 - 14s - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.7337e-04 - val_accuracy: 1.0000 - lr: 4.7831e-07 - 14s/epoch - 1s/step\n",
            "Epoch 253/300\n",
            "10/10 - 14s - loss: 0.0036 - accuracy: 0.9984 - val_loss: 1.7146e-04 - val_accuracy: 1.0000 - lr: 4.6396e-07 - 14s/epoch - 1s/step\n",
            "Epoch 254/300\n",
            "10/10 - 14s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7358e-04 - val_accuracy: 1.0000 - lr: 4.5004e-07 - 14s/epoch - 1s/step\n",
            "Epoch 255/300\n",
            "10/10 - 14s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.7749e-04 - val_accuracy: 1.0000 - lr: 4.3654e-07 - 14s/epoch - 1s/step\n",
            "Epoch 256/300\n",
            "10/10 - 14s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7602e-04 - val_accuracy: 1.0000 - lr: 4.2344e-07 - 14s/epoch - 1s/step\n",
            "Epoch 257/300\n",
            "10/10 - 15s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7404e-04 - val_accuracy: 1.0000 - lr: 4.1074e-07 - 15s/epoch - 2s/step\n",
            "Epoch 258/300\n",
            "10/10 - 15s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7695e-04 - val_accuracy: 1.0000 - lr: 3.9842e-07 - 15s/epoch - 2s/step\n",
            "Epoch 259/300\n",
            "10/10 - 15s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7762e-04 - val_accuracy: 1.0000 - lr: 3.8646e-07 - 15s/epoch - 2s/step\n",
            "Epoch 260/300\n",
            "10/10 - 16s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.7690e-04 - val_accuracy: 1.0000 - lr: 3.7487e-07 - 16s/epoch - 2s/step\n",
            "Epoch 261/300\n",
            "10/10 - 15s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7820e-04 - val_accuracy: 1.0000 - lr: 3.6362e-07 - 15s/epoch - 2s/step\n",
            "Epoch 262/300\n",
            "10/10 - 15s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8040e-04 - val_accuracy: 1.0000 - lr: 3.5271e-07 - 15s/epoch - 1s/step\n",
            "Epoch 263/300\n",
            "10/10 - 14s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7975e-04 - val_accuracy: 1.0000 - lr: 3.4213e-07 - 14s/epoch - 1s/step\n",
            "Epoch 264/300\n",
            "10/10 - 14s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8460e-04 - val_accuracy: 1.0000 - lr: 3.3187e-07 - 14s/epoch - 1s/step\n",
            "Epoch 265/300\n",
            "10/10 - 15s - loss: 0.0048 - accuracy: 0.9984 - val_loss: 1.9333e-04 - val_accuracy: 1.0000 - lr: 3.2191e-07 - 15s/epoch - 2s/step\n",
            "Epoch 266/300\n",
            "10/10 - 15s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8872e-04 - val_accuracy: 1.0000 - lr: 3.1226e-07 - 15s/epoch - 2s/step\n",
            "Epoch 267/300\n",
            "10/10 - 15s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.8622e-04 - val_accuracy: 1.0000 - lr: 3.0289e-07 - 15s/epoch - 1s/step\n",
            "Epoch 268/300\n",
            "10/10 - 15s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.8650e-04 - val_accuracy: 1.0000 - lr: 2.9380e-07 - 15s/epoch - 1s/step\n",
            "Epoch 269/300\n",
            "10/10 - 15s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8812e-04 - val_accuracy: 1.0000 - lr: 2.8499e-07 - 15s/epoch - 2s/step\n",
            "Epoch 270/300\n",
            "10/10 - 14s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.8515e-04 - val_accuracy: 1.0000 - lr: 2.7644e-07 - 14s/epoch - 1s/step\n",
            "Epoch 271/300\n",
            "10/10 - 14s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8091e-04 - val_accuracy: 1.0000 - lr: 2.6814e-07 - 14s/epoch - 1s/step\n",
            "Epoch 272/300\n",
            "10/10 - 14s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.7944e-04 - val_accuracy: 1.0000 - lr: 2.6010e-07 - 14s/epoch - 1s/step\n",
            "Epoch 273/300\n",
            "10/10 - 14s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.8213e-04 - val_accuracy: 1.0000 - lr: 2.5230e-07 - 14s/epoch - 1s/step\n",
            "Epoch 274/300\n",
            "10/10 - 14s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8506e-04 - val_accuracy: 1.0000 - lr: 2.4473e-07 - 14s/epoch - 1s/step\n",
            "Epoch 275/300\n",
            "10/10 - 13s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8784e-04 - val_accuracy: 1.0000 - lr: 2.3739e-07 - 13s/epoch - 1s/step\n",
            "Epoch 276/300\n",
            "10/10 - 14s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8590e-04 - val_accuracy: 1.0000 - lr: 2.3026e-07 - 14s/epoch - 1s/step\n",
            "Epoch 277/300\n",
            "10/10 - 14s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7861e-04 - val_accuracy: 1.0000 - lr: 2.2336e-07 - 14s/epoch - 1s/step\n",
            "Epoch 278/300\n",
            "10/10 - 14s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.7604e-04 - val_accuracy: 1.0000 - lr: 2.1666e-07 - 14s/epoch - 1s/step\n",
            "Epoch 279/300\n",
            "10/10 - 14s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7619e-04 - val_accuracy: 1.0000 - lr: 2.1016e-07 - 14s/epoch - 1s/step\n",
            "Epoch 280/300\n",
            "10/10 - 13s - loss: 0.0048 - accuracy: 0.9984 - val_loss: 1.7590e-04 - val_accuracy: 1.0000 - lr: 2.0385e-07 - 13s/epoch - 1s/step\n",
            "Epoch 281/300\n",
            "10/10 - 13s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7503e-04 - val_accuracy: 1.0000 - lr: 1.9774e-07 - 13s/epoch - 1s/step\n",
            "Epoch 282/300\n",
            "10/10 - 15s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7370e-04 - val_accuracy: 1.0000 - lr: 1.9180e-07 - 15s/epoch - 1s/step\n",
            "Epoch 283/300\n",
            "10/10 - 14s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7271e-04 - val_accuracy: 1.0000 - lr: 1.8605e-07 - 14s/epoch - 1s/step\n",
            "Epoch 284/300\n",
            "10/10 - 14s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7255e-04 - val_accuracy: 1.0000 - lr: 1.8047e-07 - 14s/epoch - 1s/step\n",
            "Epoch 285/300\n",
            "10/10 - 14s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7429e-04 - val_accuracy: 1.0000 - lr: 1.7505e-07 - 14s/epoch - 1s/step\n",
            "Epoch 286/300\n",
            "10/10 - 15s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.7571e-04 - val_accuracy: 1.0000 - lr: 1.6980e-07 - 15s/epoch - 1s/step\n",
            "Epoch 287/300\n",
            "10/10 - 14s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.7648e-04 - val_accuracy: 1.0000 - lr: 1.6471e-07 - 14s/epoch - 1s/step\n",
            "Epoch 288/300\n",
            "10/10 - 14s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.7444e-04 - val_accuracy: 1.0000 - lr: 1.5977e-07 - 14s/epoch - 1s/step\n",
            "Epoch 289/300\n",
            "10/10 - 14s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.7363e-04 - val_accuracy: 1.0000 - lr: 1.5497e-07 - 14s/epoch - 1s/step\n",
            "Epoch 290/300\n",
            "10/10 - 14s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.7576e-04 - val_accuracy: 1.0000 - lr: 1.5032e-07 - 14s/epoch - 1s/step\n",
            "Epoch 291/300\n",
            "10/10 - 14s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7848e-04 - val_accuracy: 1.0000 - lr: 1.4582e-07 - 14s/epoch - 1s/step\n",
            "Epoch 292/300\n",
            "10/10 - 13s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8017e-04 - val_accuracy: 1.0000 - lr: 1.4144e-07 - 13s/epoch - 1s/step\n",
            "Epoch 293/300\n",
            "10/10 - 14s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.8126e-04 - val_accuracy: 1.0000 - lr: 1.3720e-07 - 14s/epoch - 1s/step\n",
            "Epoch 294/300\n",
            "10/10 - 13s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8118e-04 - val_accuracy: 1.0000 - lr: 1.3308e-07 - 13s/epoch - 1s/step\n",
            "Epoch 295/300\n",
            "10/10 - 13s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.8236e-04 - val_accuracy: 1.0000 - lr: 1.2909e-07 - 13s/epoch - 1s/step\n",
            "Epoch 296/300\n",
            "10/10 - 14s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.8326e-04 - val_accuracy: 1.0000 - lr: 1.2522e-07 - 14s/epoch - 1s/step\n",
            "Epoch 297/300\n",
            "10/10 - 14s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.8342e-04 - val_accuracy: 1.0000 - lr: 1.2146e-07 - 14s/epoch - 1s/step\n",
            "Epoch 298/300\n",
            "10/10 - 14s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.8563e-04 - val_accuracy: 1.0000 - lr: 1.1782e-07 - 14s/epoch - 1s/step\n",
            "Epoch 299/300\n",
            "10/10 - 15s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8518e-04 - val_accuracy: 1.0000 - lr: 1.1428e-07 - 15s/epoch - 1s/step\n",
            "Epoch 300/300\n",
            "10/10 - 14s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8097e-04 - val_accuracy: 1.0000 - lr: 1.1085e-07 - 14s/epoch - 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = stft_model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "1sQqMIzvZm0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822959b6-b687-4010-b26d-2fdfb0c321db"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}