{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uYW-Bo6G_uE",
        "outputId": "5888b2eb-48d5-4999-9aca-3be8542e10fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Selected Channels: 15 (Fp1, Fp2, F3, F4, Cz, P3, P4, C3, C4, Cz, P3, P4, Pz, O1, O2)\n",
        "- Range of Delta (for Artificial Data Generation): [0.0001, 0.0005]\n",
        "- Input size: (65, 198, 15)\n",
        "- Input type: Short Time Fourier Transform with window length 128, overlap 100\n",
        "- Number of samples: 1212 (1200 fake samples + 12 real samples)"
      ],
      "metadata": {
        "id": "3fWvMz6Me6Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "path = '/content/drive/My Drive/ML/'\n",
        "stft = np.load(path + 'Fstft3.npy')"
      ],
      "metadata": {
        "id": "F0mipD98HCfw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 4\n",
        "\n",
        "output_values = np.concatenate((np.tile(0, 303), np.tile(1, 303), np.tile(2, 303), np.tile(3, 303)))\n",
        "output_values = np.eye(num_classes)[output_values]\n",
        "\n",
        "data_array = stft"
      ],
      "metadata": {
        "id": "g2QMu4pLHGoi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1Y1xel9HJuN",
        "outputId": "7de93640-90a5-4ce2-818b-b8610a652638"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1212, 15, 65, 198)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import zoom\n",
        "\n",
        "def resize_stft_matrix(stft_matrix, target_shape):\n",
        "    num_samples, num_channels, spec_rows, spec_cols = stft_matrix.shape\n",
        "\n",
        "    # Compute the scale factors for each dimension\n",
        "    scale_factors = (target_shape[0] / spec_rows, target_shape[1] / spec_cols)\n",
        "\n",
        "    # Perform bicubic interpolation to resize the STFT matrix\n",
        "    resized_stft_matrix = zoom(stft_matrix, (1, 1, *scale_factors), mode='reflect', order=3)\n",
        "\n",
        "    return resized_stft_matrix\n",
        "\n",
        "# Assuming 'stft_matrix' is the input STFT matrix of size (1200, 15, 65, 120)\n",
        "target_shape = (65, 65)\n",
        "\n",
        "resized_stft_matrix = resize_stft_matrix(data_array, target_shape)\n"
      ],
      "metadata": {
        "id": "zr_Mjcl8fWLV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_array = resized_stft_matrix\n",
        "data_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCwmvkcdhVAi",
        "outputId": "bb5825f5-62b2-46ee-b593-82c4c2eaf980"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1212, 15, 65, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "uClYKYWoJpaV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "metadata": {
        "id": "TxBsjSrTwxsq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "train_params = {'dim': (65,65),\n",
        "                'batch_size': 64,\n",
        "                'n_classes':4,\n",
        "                'n_channels': 15,\n",
        "                'shuffle': True,\n",
        "                'input_type': 'stft',\n",
        "                'augment': True\n",
        "               }\n",
        "val_params = {'dim': (65,65),\n",
        "              'batch_size': 64,\n",
        "              'n_classes':4,\n",
        "              'n_channels': 15,\n",
        "              'shuffle': False,\n",
        "              'input_type': 'stft',\n",
        "              'augment': False\n",
        "             }"
      ],
      "metadata": {
        "id": "Suq5cIkUxHuu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "\n",
        "def mish(inputs):\n",
        "  x = tf.nn.softplus(inputs)\n",
        "  x = tf.nn.tanh(x)\n",
        "  x = tf.multiply(x, inputs)\n",
        "  return x\n",
        "\n",
        "\n",
        "stft_input = keras.Input(shape=(65, 65, 15))\n",
        "x = Conv2D(32, 3, activation=mish)(stft_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, 3, activation=mish)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, 5, strides=2, padding='same', activation=mish)(x)\n",
        "x  = Concatenate(axis=-1)([MaxPooling2D((1, 2))(x), AveragePooling2D((1, 2))(x)])\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "x = Conv2D(64, 3, activation=mish)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, 3, activation=mish)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, 5, strides=2, padding='same', activation=mish)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "x = Conv2D(128, 4, activation=mish)(x)\n",
        "# x  = Concatenate(axis=-1)([MaxPooling2D((1, 2))(x), AveragePooling2D((1, 2))(x)])\n",
        "x = BatchNormalization()(x)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "stft_prediction = Dense(4, activation='softmax')(x)\n",
        "\n",
        "stft_model = Model(stft_input, stft_prediction)\n",
        "\n",
        "stft_model.compile(optimizer = 'adam',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=[\"accuracy\"])\n",
        "\n",
        "stft_model.summary()\n",
        "\n",
        "stft_annealer = LearningRateScheduler(lambda x: 1e-3 * 0.97 ** x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEgxh0_nxKvr",
        "outputId": "6a441a5d-ae38-4cd0-b70d-777420cc2794"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 65, 65, 15)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 63, 63, 32)   4352        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 63, 63, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 61, 61, 32)   9248        ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 61, 61, 32)  128         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 31, 31, 32)   25632       ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 31, 15, 32)   0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 31, 15, 32)  0           ['conv2d_2[0][0]']               \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 31, 15, 64)   0           ['max_pooling2d[0][0]',          \n",
            "                                                                  'average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 31, 15, 64)   0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 29, 13, 64)   36928       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 29, 13, 64)  256         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 27, 11, 64)   36928       ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 27, 11, 64)  256         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 14, 6, 64)    102464      ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 14, 6, 64)   256         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 14, 6, 64)    0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 11, 3, 128)   131200      ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 11, 3, 128)  512         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 4224)         0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 4224)         0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 4)            16900       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 365,188\n",
            "Trainable params: 364,420\n",
            "Non-trainable params: 768\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_array.shape\n",
        "\n",
        "input = np.abs(np.transpose(data_array[:, :, :, :], (0, 2, 3, 1)))\n",
        "print(input.shape)\n",
        "\n",
        "X_train_temp, X_test, Y_train_temp, Y_test = train_test_split(input, output_values, test_size=0.3, random_state=42)\n",
        "X_train, X_validate, Y_train, Y_validate = train_test_split(X_train_temp, Y_train_temp, test_size=0.25, random_state=36)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh_eHtWux0R0",
        "outputId": "0820a65c-bcd8-4cdb-8b3d-c148a30ac8b2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1212, 65, 65, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stft_history = stft_model.fit(X_train, Y_train, batch_size = 64, epochs = 300,\n",
        "                        verbose = 2, validation_data=(X_validate, Y_validate),\n",
        "                        callbacks=[stft_annealer], class_weight = {})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6slOiR_yCzo",
        "outputId": "16e3cda3-eea6-46c6-dd87-a95b28e94624"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "10/10 - 30s - loss: 2.2587 - accuracy: 0.2752 - val_loss: 1.3883 - val_accuracy: 0.2406 - lr: 0.0010 - 30s/epoch - 3s/step\n",
            "Epoch 2/300\n",
            "10/10 - 25s - loss: 2.2659 - accuracy: 0.2657 - val_loss: 1.3910 - val_accuracy: 0.2406 - lr: 9.7000e-04 - 25s/epoch - 3s/step\n",
            "Epoch 3/300\n",
            "10/10 - 26s - loss: 2.1194 - accuracy: 0.3176 - val_loss: 1.3908 - val_accuracy: 0.2406 - lr: 9.4090e-04 - 26s/epoch - 3s/step\n",
            "Epoch 4/300\n",
            "10/10 - 27s - loss: 1.8854 - accuracy: 0.3931 - val_loss: 1.3978 - val_accuracy: 0.2689 - lr: 9.1267e-04 - 27s/epoch - 3s/step\n",
            "Epoch 5/300\n",
            "10/10 - 24s - loss: 1.4825 - accuracy: 0.4843 - val_loss: 1.4506 - val_accuracy: 0.2689 - lr: 8.8529e-04 - 24s/epoch - 2s/step\n",
            "Epoch 6/300\n",
            "10/10 - 25s - loss: 1.1425 - accuracy: 0.5755 - val_loss: 1.5584 - val_accuracy: 0.2689 - lr: 8.5873e-04 - 25s/epoch - 3s/step\n",
            "Epoch 7/300\n",
            "10/10 - 26s - loss: 0.8532 - accuracy: 0.6855 - val_loss: 1.6867 - val_accuracy: 0.2689 - lr: 8.3297e-04 - 26s/epoch - 3s/step\n",
            "Epoch 8/300\n",
            "10/10 - 25s - loss: 0.5055 - accuracy: 0.7956 - val_loss: 1.7615 - val_accuracy: 0.2689 - lr: 8.0798e-04 - 25s/epoch - 3s/step\n",
            "Epoch 9/300\n",
            "10/10 - 24s - loss: 0.2335 - accuracy: 0.9009 - val_loss: 1.8766 - val_accuracy: 0.2689 - lr: 7.8374e-04 - 24s/epoch - 2s/step\n",
            "Epoch 10/300\n",
            "10/10 - 32s - loss: 0.1095 - accuracy: 0.9638 - val_loss: 1.7741 - val_accuracy: 0.2689 - lr: 7.6023e-04 - 32s/epoch - 3s/step\n",
            "Epoch 11/300\n",
            "10/10 - 25s - loss: 0.0399 - accuracy: 0.9937 - val_loss: 2.0273 - val_accuracy: 0.2689 - lr: 7.3742e-04 - 25s/epoch - 2s/step\n",
            "Epoch 12/300\n",
            "10/10 - 25s - loss: 0.0183 - accuracy: 0.9984 - val_loss: 1.9779 - val_accuracy: 0.2689 - lr: 7.1530e-04 - 25s/epoch - 3s/step\n",
            "Epoch 13/300\n",
            "10/10 - 27s - loss: 0.0103 - accuracy: 0.9984 - val_loss: 2.2096 - val_accuracy: 0.2689 - lr: 6.9384e-04 - 27s/epoch - 3s/step\n",
            "Epoch 14/300\n",
            "10/10 - 27s - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.1860 - val_accuracy: 0.2689 - lr: 6.7303e-04 - 27s/epoch - 3s/step\n",
            "Epoch 15/300\n",
            "10/10 - 24s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1399 - val_accuracy: 0.2689 - lr: 6.5284e-04 - 24s/epoch - 2s/step\n",
            "Epoch 16/300\n",
            "10/10 - 27s - loss: 0.0055 - accuracy: 0.9984 - val_loss: 2.2667 - val_accuracy: 0.2689 - lr: 6.3325e-04 - 27s/epoch - 3s/step\n",
            "Epoch 17/300\n",
            "10/10 - 26s - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4258 - val_accuracy: 0.2689 - lr: 6.1425e-04 - 26s/epoch - 3s/step\n",
            "Epoch 18/300\n",
            "10/10 - 25s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.6934 - val_accuracy: 0.2689 - lr: 5.9583e-04 - 25s/epoch - 3s/step\n",
            "Epoch 19/300\n",
            "10/10 - 24s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8260 - val_accuracy: 0.2689 - lr: 5.7795e-04 - 24s/epoch - 2s/step\n",
            "Epoch 20/300\n",
            "10/10 - 25s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9334 - val_accuracy: 0.2689 - lr: 5.6061e-04 - 25s/epoch - 3s/step\n",
            "Epoch 21/300\n",
            "10/10 - 26s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1214 - val_accuracy: 0.2689 - lr: 5.4379e-04 - 26s/epoch - 3s/step\n",
            "Epoch 22/300\n",
            "10/10 - 26s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.3659 - val_accuracy: 0.2689 - lr: 5.2748e-04 - 26s/epoch - 3s/step\n",
            "Epoch 23/300\n",
            "10/10 - 23s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.2716 - val_accuracy: 0.2689 - lr: 5.1166e-04 - 23s/epoch - 2s/step\n",
            "Epoch 24/300\n",
            "10/10 - 26s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9987 - val_accuracy: 0.2689 - lr: 4.9631e-04 - 26s/epoch - 3s/step\n",
            "Epoch 25/300\n",
            "10/10 - 26s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0764 - val_accuracy: 0.2689 - lr: 4.8142e-04 - 26s/epoch - 3s/step\n",
            "Epoch 26/300\n",
            "10/10 - 27s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.3379 - val_accuracy: 0.2689 - lr: 4.6697e-04 - 27s/epoch - 3s/step\n",
            "Epoch 27/300\n",
            "10/10 - 24s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.6956 - val_accuracy: 0.2689 - lr: 4.5297e-04 - 24s/epoch - 2s/step\n",
            "Epoch 28/300\n",
            "10/10 - 24s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.9053 - val_accuracy: 0.2689 - lr: 4.3938e-04 - 24s/epoch - 2s/step\n",
            "Epoch 29/300\n",
            "10/10 - 28s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.8434 - val_accuracy: 0.2689 - lr: 4.2620e-04 - 28s/epoch - 3s/step\n",
            "Epoch 30/300\n",
            "10/10 - 26s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.7425 - val_accuracy: 0.2689 - lr: 4.1341e-04 - 26s/epoch - 3s/step\n",
            "Epoch 31/300\n",
            "10/10 - 26s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.9937 - val_accuracy: 0.2689 - lr: 4.0101e-04 - 26s/epoch - 3s/step\n",
            "Epoch 32/300\n",
            "10/10 - 24s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.8522 - val_accuracy: 0.2689 - lr: 3.8898e-04 - 24s/epoch - 2s/step\n",
            "Epoch 33/300\n",
            "10/10 - 26s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4606 - val_accuracy: 0.3396 - lr: 3.7731e-04 - 26s/epoch - 3s/step\n",
            "Epoch 34/300\n",
            "10/10 - 26s - loss: 8.6927e-04 - accuracy: 1.0000 - val_loss: 1.5519 - val_accuracy: 0.2453 - lr: 3.6599e-04 - 26s/epoch - 3s/step\n",
            "Epoch 35/300\n",
            "10/10 - 26s - loss: 9.3373e-04 - accuracy: 1.0000 - val_loss: 1.7188 - val_accuracy: 0.2453 - lr: 3.5501e-04 - 26s/epoch - 3s/step\n",
            "Epoch 36/300\n",
            "10/10 - 23s - loss: 8.9607e-04 - accuracy: 1.0000 - val_loss: 2.0394 - val_accuracy: 0.2453 - lr: 3.4436e-04 - 23s/epoch - 2s/step\n",
            "Epoch 37/300\n",
            "10/10 - 26s - loss: 7.0901e-04 - accuracy: 1.0000 - val_loss: 2.2799 - val_accuracy: 0.2453 - lr: 3.3403e-04 - 26s/epoch - 3s/step\n",
            "Epoch 38/300\n",
            "10/10 - 25s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.1381 - val_accuracy: 0.2453 - lr: 3.2401e-04 - 25s/epoch - 2s/step\n",
            "Epoch 39/300\n",
            "10/10 - 23s - loss: 6.3666e-04 - accuracy: 1.0000 - val_loss: 1.6303 - val_accuracy: 0.2453 - lr: 3.1429e-04 - 23s/epoch - 2s/step\n",
            "Epoch 40/300\n",
            "10/10 - 24s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3735 - val_accuracy: 0.2689 - lr: 3.0486e-04 - 24s/epoch - 2s/step\n",
            "Epoch 41/300\n",
            "10/10 - 25s - loss: 8.8645e-04 - accuracy: 1.0000 - val_loss: 7.5574 - val_accuracy: 0.2689 - lr: 2.9571e-04 - 25s/epoch - 2s/step\n",
            "Epoch 42/300\n",
            "10/10 - 23s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 18.3890 - val_accuracy: 0.2689 - lr: 2.8684e-04 - 23s/epoch - 2s/step\n",
            "Epoch 43/300\n",
            "10/10 - 25s - loss: 7.5607e-04 - accuracy: 1.0000 - val_loss: 28.3205 - val_accuracy: 0.2689 - lr: 2.7824e-04 - 25s/epoch - 3s/step\n",
            "Epoch 44/300\n",
            "10/10 - 25s - loss: 8.9132e-04 - accuracy: 1.0000 - val_loss: 39.2898 - val_accuracy: 0.2689 - lr: 2.6989e-04 - 25s/epoch - 3s/step\n",
            "Epoch 45/300\n",
            "10/10 - 23s - loss: 6.5396e-04 - accuracy: 1.0000 - val_loss: 44.1786 - val_accuracy: 0.2689 - lr: 2.6179e-04 - 23s/epoch - 2s/step\n",
            "Epoch 46/300\n",
            "10/10 - 24s - loss: 8.1311e-04 - accuracy: 1.0000 - val_loss: 40.0046 - val_accuracy: 0.2689 - lr: 2.5394e-04 - 24s/epoch - 2s/step\n",
            "Epoch 47/300\n",
            "10/10 - 25s - loss: 8.3286e-04 - accuracy: 1.0000 - val_loss: 24.5291 - val_accuracy: 0.2689 - lr: 2.4632e-04 - 25s/epoch - 2s/step\n",
            "Epoch 48/300\n",
            "10/10 - 22s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.7974 - val_accuracy: 0.2689 - lr: 2.3893e-04 - 22s/epoch - 2s/step\n",
            "Epoch 49/300\n",
            "10/10 - 25s - loss: 5.9951e-04 - accuracy: 1.0000 - val_loss: 4.3782 - val_accuracy: 0.2689 - lr: 2.3176e-04 - 25s/epoch - 3s/step\n",
            "Epoch 50/300\n",
            "10/10 - 25s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 19.0290 - val_accuracy: 0.2689 - lr: 2.2481e-04 - 25s/epoch - 2s/step\n",
            "Epoch 51/300\n",
            "10/10 - 22s - loss: 6.8955e-04 - accuracy: 1.0000 - val_loss: 33.3459 - val_accuracy: 0.2689 - lr: 2.1807e-04 - 22s/epoch - 2s/step\n",
            "Epoch 52/300\n",
            "10/10 - 25s - loss: 8.5047e-04 - accuracy: 1.0000 - val_loss: 46.1645 - val_accuracy: 0.2689 - lr: 2.1152e-04 - 25s/epoch - 2s/step\n",
            "Epoch 53/300\n",
            "10/10 - 24s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 62.4393 - val_accuracy: 0.2689 - lr: 2.0518e-04 - 24s/epoch - 2s/step\n",
            "Epoch 54/300\n",
            "10/10 - 22s - loss: 8.3503e-04 - accuracy: 1.0000 - val_loss: 99.0234 - val_accuracy: 0.2689 - lr: 1.9902e-04 - 22s/epoch - 2s/step\n",
            "Epoch 55/300\n",
            "10/10 - 25s - loss: 4.5245e-04 - accuracy: 1.0000 - val_loss: 120.4384 - val_accuracy: 0.2689 - lr: 1.9305e-04 - 25s/epoch - 3s/step\n",
            "Epoch 56/300\n",
            "10/10 - 27s - loss: 6.2007e-04 - accuracy: 1.0000 - val_loss: 133.7686 - val_accuracy: 0.2689 - lr: 1.8726e-04 - 27s/epoch - 3s/step\n",
            "Epoch 57/300\n",
            "10/10 - 23s - loss: 4.2298e-04 - accuracy: 1.0000 - val_loss: 130.1081 - val_accuracy: 0.2689 - lr: 1.8164e-04 - 23s/epoch - 2s/step\n",
            "Epoch 58/300\n",
            "10/10 - 24s - loss: 5.9565e-04 - accuracy: 1.0000 - val_loss: 134.3066 - val_accuracy: 0.2689 - lr: 1.7619e-04 - 24s/epoch - 2s/step\n",
            "Epoch 59/300\n",
            "10/10 - 26s - loss: 8.3546e-04 - accuracy: 1.0000 - val_loss: 120.0023 - val_accuracy: 0.2689 - lr: 1.7091e-04 - 26s/epoch - 3s/step\n",
            "Epoch 60/300\n",
            "10/10 - 26s - loss: 8.0377e-04 - accuracy: 1.0000 - val_loss: 79.3493 - val_accuracy: 0.2689 - lr: 1.6578e-04 - 26s/epoch - 3s/step\n",
            "Epoch 61/300\n",
            "10/10 - 24s - loss: 4.4911e-04 - accuracy: 1.0000 - val_loss: 41.5619 - val_accuracy: 0.2689 - lr: 1.6081e-04 - 24s/epoch - 2s/step\n",
            "Epoch 62/300\n",
            "10/10 - 25s - loss: 6.7453e-04 - accuracy: 1.0000 - val_loss: 24.8070 - val_accuracy: 0.2689 - lr: 1.5598e-04 - 25s/epoch - 3s/step\n",
            "Epoch 63/300\n",
            "10/10 - 26s - loss: 4.9919e-04 - accuracy: 1.0000 - val_loss: 24.1859 - val_accuracy: 0.2689 - lr: 1.5130e-04 - 26s/epoch - 3s/step\n",
            "Epoch 64/300\n",
            "10/10 - 24s - loss: 6.8745e-04 - accuracy: 1.0000 - val_loss: 12.4244 - val_accuracy: 0.2689 - lr: 1.4676e-04 - 24s/epoch - 2s/step\n",
            "Epoch 65/300\n",
            "10/10 - 24s - loss: 3.8874e-04 - accuracy: 1.0000 - val_loss: 9.5497 - val_accuracy: 0.2689 - lr: 1.4236e-04 - 24s/epoch - 2s/step\n",
            "Epoch 66/300\n",
            "10/10 - 26s - loss: 4.5704e-04 - accuracy: 1.0000 - val_loss: 10.0740 - val_accuracy: 0.2689 - lr: 1.3809e-04 - 26s/epoch - 3s/step\n",
            "Epoch 67/300\n",
            "10/10 - 25s - loss: 7.1719e-04 - accuracy: 1.0000 - val_loss: 11.7286 - val_accuracy: 0.2689 - lr: 1.3395e-04 - 25s/epoch - 2s/step\n",
            "Epoch 68/300\n",
            "10/10 - 23s - loss: 3.2521e-04 - accuracy: 1.0000 - val_loss: 9.1496 - val_accuracy: 0.2689 - lr: 1.2993e-04 - 23s/epoch - 2s/step\n",
            "Epoch 69/300\n",
            "10/10 - 25s - loss: 3.7241e-04 - accuracy: 1.0000 - val_loss: 3.4980 - val_accuracy: 0.2689 - lr: 1.2603e-04 - 25s/epoch - 2s/step\n",
            "Epoch 70/300\n",
            "10/10 - 27s - loss: 3.7146e-04 - accuracy: 1.0000 - val_loss: 2.4012 - val_accuracy: 0.5142 - lr: 1.2225e-04 - 27s/epoch - 3s/step\n",
            "Epoch 71/300\n",
            "10/10 - 24s - loss: 5.1237e-04 - accuracy: 1.0000 - val_loss: 5.7790 - val_accuracy: 0.2453 - lr: 1.1858e-04 - 24s/epoch - 2s/step\n",
            "Epoch 72/300\n",
            "10/10 - 25s - loss: 5.3784e-04 - accuracy: 1.0000 - val_loss: 2.7102 - val_accuracy: 0.5708 - lr: 1.1503e-04 - 25s/epoch - 2s/step\n",
            "Epoch 73/300\n",
            "10/10 - 25s - loss: 4.0113e-04 - accuracy: 1.0000 - val_loss: 25.0180 - val_accuracy: 0.2689 - lr: 1.1157e-04 - 25s/epoch - 2s/step\n",
            "Epoch 74/300\n",
            "10/10 - 26s - loss: 9.3459e-04 - accuracy: 1.0000 - val_loss: 44.6262 - val_accuracy: 0.2689 - lr: 1.0823e-04 - 26s/epoch - 3s/step\n",
            "Epoch 75/300\n",
            "10/10 - 23s - loss: 7.7283e-04 - accuracy: 1.0000 - val_loss: 46.8337 - val_accuracy: 0.2689 - lr: 1.0498e-04 - 23s/epoch - 2s/step\n",
            "Epoch 76/300\n",
            "10/10 - 26s - loss: 6.1677e-04 - accuracy: 1.0000 - val_loss: 26.3049 - val_accuracy: 0.2689 - lr: 1.0183e-04 - 26s/epoch - 3s/step\n",
            "Epoch 77/300\n",
            "10/10 - 25s - loss: 5.6152e-04 - accuracy: 1.0000 - val_loss: 59.3123 - val_accuracy: 0.2689 - lr: 9.8776e-05 - 25s/epoch - 3s/step\n",
            "Epoch 78/300\n",
            "10/10 - 27s - loss: 5.9133e-04 - accuracy: 1.0000 - val_loss: 89.2561 - val_accuracy: 0.2689 - lr: 9.5813e-05 - 27s/epoch - 3s/step\n",
            "Epoch 79/300\n",
            "10/10 - 23s - loss: 3.6038e-04 - accuracy: 1.0000 - val_loss: 168.6616 - val_accuracy: 0.2689 - lr: 9.2938e-05 - 23s/epoch - 2s/step\n",
            "Epoch 80/300\n",
            "10/10 - 24s - loss: 2.8562e-04 - accuracy: 1.0000 - val_loss: 202.0241 - val_accuracy: 0.2689 - lr: 9.0150e-05 - 24s/epoch - 2s/step\n",
            "Epoch 81/300\n",
            "10/10 - 26s - loss: 4.9100e-04 - accuracy: 1.0000 - val_loss: 307.9863 - val_accuracy: 0.2689 - lr: 8.7446e-05 - 26s/epoch - 3s/step\n",
            "Epoch 82/300\n",
            "10/10 - 23s - loss: 5.4780e-04 - accuracy: 1.0000 - val_loss: 391.6880 - val_accuracy: 0.2689 - lr: 8.4822e-05 - 23s/epoch - 2s/step\n",
            "Epoch 83/300\n",
            "10/10 - 25s - loss: 4.8216e-04 - accuracy: 1.0000 - val_loss: 325.1751 - val_accuracy: 0.2689 - lr: 8.2278e-05 - 25s/epoch - 2s/step\n",
            "Epoch 84/300\n",
            "10/10 - 25s - loss: 3.7699e-04 - accuracy: 1.0000 - val_loss: 343.3174 - val_accuracy: 0.2689 - lr: 7.9809e-05 - 25s/epoch - 3s/step\n",
            "Epoch 85/300\n",
            "10/10 - 26s - loss: 3.8034e-04 - accuracy: 1.0000 - val_loss: 364.7625 - val_accuracy: 0.2689 - lr: 7.7415e-05 - 26s/epoch - 3s/step\n",
            "Epoch 86/300\n",
            "10/10 - 23s - loss: 4.5253e-04 - accuracy: 1.0000 - val_loss: 456.4697 - val_accuracy: 0.2689 - lr: 7.5093e-05 - 23s/epoch - 2s/step\n",
            "Epoch 87/300\n",
            "10/10 - 24s - loss: 5.9100e-04 - accuracy: 1.0000 - val_loss: 482.6177 - val_accuracy: 0.2689 - lr: 7.2840e-05 - 24s/epoch - 2s/step\n",
            "Epoch 88/300\n",
            "10/10 - 26s - loss: 4.0417e-04 - accuracy: 1.0000 - val_loss: 621.3044 - val_accuracy: 0.2689 - lr: 7.0655e-05 - 26s/epoch - 3s/step\n",
            "Epoch 89/300\n",
            "10/10 - 23s - loss: 6.4463e-04 - accuracy: 1.0000 - val_loss: 751.2705 - val_accuracy: 0.2689 - lr: 6.8535e-05 - 23s/epoch - 2s/step\n",
            "Epoch 90/300\n",
            "10/10 - 25s - loss: 3.9846e-04 - accuracy: 1.0000 - val_loss: 780.4843 - val_accuracy: 0.2689 - lr: 6.6479e-05 - 25s/epoch - 2s/step\n",
            "Epoch 91/300\n",
            "10/10 - 25s - loss: 4.6015e-04 - accuracy: 1.0000 - val_loss: 873.8321 - val_accuracy: 0.2689 - lr: 6.4485e-05 - 25s/epoch - 2s/step\n",
            "Epoch 92/300\n",
            "10/10 - 23s - loss: 3.2390e-04 - accuracy: 1.0000 - val_loss: 940.6004 - val_accuracy: 0.2689 - lr: 6.2550e-05 - 23s/epoch - 2s/step\n",
            "Epoch 93/300\n",
            "10/10 - 26s - loss: 5.0355e-04 - accuracy: 1.0000 - val_loss: 926.8320 - val_accuracy: 0.2689 - lr: 6.0674e-05 - 26s/epoch - 3s/step\n",
            "Epoch 94/300\n",
            "10/10 - 25s - loss: 4.8526e-04 - accuracy: 1.0000 - val_loss: 850.1740 - val_accuracy: 0.2689 - lr: 5.8853e-05 - 25s/epoch - 3s/step\n",
            "Epoch 95/300\n",
            "10/10 - 26s - loss: 3.1945e-04 - accuracy: 1.0000 - val_loss: 805.4824 - val_accuracy: 0.2689 - lr: 5.7088e-05 - 26s/epoch - 3s/step\n",
            "Epoch 96/300\n",
            "10/10 - 23s - loss: 4.0677e-04 - accuracy: 1.0000 - val_loss: 802.8060 - val_accuracy: 0.2689 - lr: 5.5375e-05 - 23s/epoch - 2s/step\n",
            "Epoch 97/300\n",
            "10/10 - 24s - loss: 5.4200e-04 - accuracy: 1.0000 - val_loss: 780.3752 - val_accuracy: 0.2689 - lr: 5.3714e-05 - 24s/epoch - 2s/step\n",
            "Epoch 98/300\n",
            "10/10 - 25s - loss: 4.0595e-04 - accuracy: 1.0000 - val_loss: 671.4022 - val_accuracy: 0.2689 - lr: 5.2102e-05 - 25s/epoch - 2s/step\n",
            "Epoch 99/300\n",
            "10/10 - 23s - loss: 6.5325e-04 - accuracy: 1.0000 - val_loss: 546.9283 - val_accuracy: 0.2689 - lr: 5.0539e-05 - 23s/epoch - 2s/step\n",
            "Epoch 100/300\n",
            "10/10 - 26s - loss: 6.6644e-04 - accuracy: 1.0000 - val_loss: 474.5211 - val_accuracy: 0.2689 - lr: 4.9023e-05 - 26s/epoch - 3s/step\n",
            "Epoch 101/300\n",
            "10/10 - 26s - loss: 4.5288e-04 - accuracy: 1.0000 - val_loss: 464.0310 - val_accuracy: 0.2689 - lr: 4.7553e-05 - 26s/epoch - 3s/step\n",
            "Epoch 102/300\n",
            "10/10 - 23s - loss: 2.8332e-04 - accuracy: 1.0000 - val_loss: 442.2544 - val_accuracy: 0.2689 - lr: 4.6126e-05 - 23s/epoch - 2s/step\n",
            "Epoch 103/300\n",
            "10/10 - 25s - loss: 3.8581e-04 - accuracy: 1.0000 - val_loss: 357.1814 - val_accuracy: 0.2689 - lr: 4.4742e-05 - 25s/epoch - 2s/step\n",
            "Epoch 104/300\n",
            "10/10 - 25s - loss: 4.4018e-04 - accuracy: 1.0000 - val_loss: 146.1320 - val_accuracy: 0.2689 - lr: 4.3400e-05 - 25s/epoch - 3s/step\n",
            "Epoch 105/300\n",
            "10/10 - 26s - loss: 3.6268e-04 - accuracy: 1.0000 - val_loss: 106.8333 - val_accuracy: 0.2689 - lr: 4.2098e-05 - 26s/epoch - 3s/step\n",
            "Epoch 106/300\n",
            "10/10 - 23s - loss: 3.6546e-04 - accuracy: 1.0000 - val_loss: 155.5000 - val_accuracy: 0.2689 - lr: 4.0835e-05 - 23s/epoch - 2s/step\n",
            "Epoch 107/300\n",
            "10/10 - 26s - loss: 4.0296e-04 - accuracy: 1.0000 - val_loss: 226.9267 - val_accuracy: 0.2689 - lr: 3.9610e-05 - 26s/epoch - 3s/step\n",
            "Epoch 108/300\n",
            "10/10 - 25s - loss: 6.0759e-04 - accuracy: 1.0000 - val_loss: 221.8540 - val_accuracy: 0.2689 - lr: 3.8422e-05 - 25s/epoch - 3s/step\n",
            "Epoch 109/300\n",
            "10/10 - 23s - loss: 4.2769e-04 - accuracy: 1.0000 - val_loss: 158.8428 - val_accuracy: 0.2689 - lr: 3.7269e-05 - 23s/epoch - 2s/step\n",
            "Epoch 110/300\n",
            "10/10 - 24s - loss: 4.5784e-04 - accuracy: 1.0000 - val_loss: 149.9796 - val_accuracy: 0.2689 - lr: 3.6151e-05 - 24s/epoch - 2s/step\n",
            "Epoch 111/300\n",
            "10/10 - 24s - loss: 6.2342e-04 - accuracy: 1.0000 - val_loss: 114.5723 - val_accuracy: 0.5142 - lr: 3.5066e-05 - 24s/epoch - 2s/step\n",
            "Epoch 112/300\n",
            "10/10 - 23s - loss: 7.3707e-04 - accuracy: 1.0000 - val_loss: 78.2232 - val_accuracy: 0.5142 - lr: 3.4014e-05 - 23s/epoch - 2s/step\n",
            "Epoch 113/300\n",
            "10/10 - 25s - loss: 3.2408e-04 - accuracy: 1.0000 - val_loss: 101.1766 - val_accuracy: 0.4811 - lr: 3.2994e-05 - 25s/epoch - 3s/step\n",
            "Epoch 114/300\n",
            "10/10 - 26s - loss: 5.7191e-04 - accuracy: 1.0000 - val_loss: 155.1436 - val_accuracy: 0.2689 - lr: 3.2004e-05 - 26s/epoch - 3s/step\n",
            "Epoch 115/300\n",
            "10/10 - 26s - loss: 4.3822e-04 - accuracy: 1.0000 - val_loss: 284.3887 - val_accuracy: 0.2689 - lr: 3.1044e-05 - 26s/epoch - 3s/step\n",
            "Epoch 116/300\n",
            "10/10 - 23s - loss: 6.6580e-04 - accuracy: 1.0000 - val_loss: 437.7206 - val_accuracy: 0.2689 - lr: 3.0113e-05 - 23s/epoch - 2s/step\n",
            "Epoch 117/300\n",
            "10/10 - 25s - loss: 8.0542e-04 - accuracy: 1.0000 - val_loss: 579.2026 - val_accuracy: 0.2689 - lr: 2.9209e-05 - 25s/epoch - 2s/step\n",
            "Epoch 118/300\n",
            "10/10 - 25s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 410.2072 - val_accuracy: 0.2689 - lr: 2.8333e-05 - 25s/epoch - 3s/step\n",
            "Epoch 119/300\n",
            "10/10 - 23s - loss: 5.1625e-04 - accuracy: 1.0000 - val_loss: 178.5293 - val_accuracy: 0.2689 - lr: 2.7483e-05 - 23s/epoch - 2s/step\n",
            "Epoch 120/300\n",
            "10/10 - 25s - loss: 5.2963e-04 - accuracy: 1.0000 - val_loss: 43.2175 - val_accuracy: 0.5142 - lr: 2.6659e-05 - 25s/epoch - 3s/step\n",
            "Epoch 121/300\n",
            "10/10 - 25s - loss: 4.2633e-04 - accuracy: 1.0000 - val_loss: 2.3427 - val_accuracy: 0.6698 - lr: 2.5859e-05 - 25s/epoch - 2s/step\n",
            "Epoch 122/300\n",
            "10/10 - 23s - loss: 4.8885e-04 - accuracy: 1.0000 - val_loss: 6.2664 - val_accuracy: 0.4009 - lr: 2.5083e-05 - 23s/epoch - 2s/step\n",
            "Epoch 123/300\n",
            "10/10 - 25s - loss: 4.9513e-04 - accuracy: 1.0000 - val_loss: 9.0264 - val_accuracy: 0.4009 - lr: 2.4331e-05 - 25s/epoch - 2s/step\n",
            "Epoch 124/300\n",
            "10/10 - 25s - loss: 7.6853e-04 - accuracy: 1.0000 - val_loss: 32.3418 - val_accuracy: 0.2453 - lr: 2.3601e-05 - 25s/epoch - 2s/step\n",
            "Epoch 125/300\n",
            "10/10 - 26s - loss: 3.0828e-04 - accuracy: 1.0000 - val_loss: 37.3791 - val_accuracy: 0.2453 - lr: 2.2893e-05 - 26s/epoch - 3s/step\n",
            "Epoch 126/300\n",
            "10/10 - 23s - loss: 5.7071e-04 - accuracy: 1.0000 - val_loss: 40.8072 - val_accuracy: 0.2453 - lr: 2.2206e-05 - 23s/epoch - 2s/step\n",
            "Epoch 127/300\n",
            "10/10 - 26s - loss: 3.4959e-04 - accuracy: 1.0000 - val_loss: 44.5700 - val_accuracy: 0.2453 - lr: 2.1540e-05 - 26s/epoch - 3s/step\n",
            "Epoch 128/300\n",
            "10/10 - 26s - loss: 7.2360e-04 - accuracy: 1.0000 - val_loss: 43.6374 - val_accuracy: 0.2453 - lr: 2.0893e-05 - 26s/epoch - 3s/step\n",
            "Epoch 129/300\n",
            "10/10 - 26s - loss: 3.9315e-04 - accuracy: 1.0000 - val_loss: 40.3793 - val_accuracy: 0.2453 - lr: 2.0267e-05 - 26s/epoch - 3s/step\n",
            "Epoch 130/300\n",
            "10/10 - 24s - loss: 3.7183e-04 - accuracy: 1.0000 - val_loss: 35.0287 - val_accuracy: 0.2453 - lr: 1.9659e-05 - 24s/epoch - 2s/step\n",
            "Epoch 131/300\n",
            "10/10 - 25s - loss: 4.7321e-04 - accuracy: 1.0000 - val_loss: 30.2652 - val_accuracy: 0.2453 - lr: 1.9069e-05 - 25s/epoch - 3s/step\n",
            "Epoch 132/300\n",
            "10/10 - 25s - loss: 4.3273e-04 - accuracy: 1.0000 - val_loss: 27.1370 - val_accuracy: 0.2453 - lr: 1.8497e-05 - 25s/epoch - 2s/step\n",
            "Epoch 133/300\n",
            "10/10 - 23s - loss: 3.1041e-04 - accuracy: 1.0000 - val_loss: 26.9628 - val_accuracy: 0.2453 - lr: 1.7942e-05 - 23s/epoch - 2s/step\n",
            "Epoch 134/300\n",
            "10/10 - 25s - loss: 3.5990e-04 - accuracy: 1.0000 - val_loss: 25.8265 - val_accuracy: 0.2453 - lr: 1.7404e-05 - 25s/epoch - 3s/step\n",
            "Epoch 135/300\n",
            "10/10 - 25s - loss: 5.7600e-04 - accuracy: 1.0000 - val_loss: 23.5225 - val_accuracy: 0.2453 - lr: 1.6882e-05 - 25s/epoch - 2s/step\n",
            "Epoch 136/300\n",
            "10/10 - 23s - loss: 3.5299e-04 - accuracy: 1.0000 - val_loss: 20.9412 - val_accuracy: 0.2453 - lr: 1.6375e-05 - 23s/epoch - 2s/step\n",
            "Epoch 137/300\n",
            "10/10 - 25s - loss: 5.1462e-04 - accuracy: 1.0000 - val_loss: 18.1027 - val_accuracy: 0.2453 - lr: 1.5884e-05 - 25s/epoch - 2s/step\n",
            "Epoch 138/300\n",
            "10/10 - 25s - loss: 3.0490e-04 - accuracy: 1.0000 - val_loss: 17.0547 - val_accuracy: 0.2453 - lr: 1.5407e-05 - 25s/epoch - 2s/step\n",
            "Epoch 139/300\n",
            "10/10 - 26s - loss: 2.6541e-04 - accuracy: 1.0000 - val_loss: 17.4126 - val_accuracy: 0.2453 - lr: 1.4945e-05 - 26s/epoch - 3s/step\n",
            "Epoch 140/300\n",
            "10/10 - 24s - loss: 4.2333e-04 - accuracy: 1.0000 - val_loss: 17.1133 - val_accuracy: 0.2453 - lr: 1.4497e-05 - 24s/epoch - 2s/step\n",
            "Epoch 141/300\n",
            "10/10 - 25s - loss: 4.5870e-04 - accuracy: 1.0000 - val_loss: 19.8948 - val_accuracy: 0.2453 - lr: 1.4062e-05 - 25s/epoch - 2s/step\n",
            "Epoch 142/300\n",
            "10/10 - 26s - loss: 3.2392e-04 - accuracy: 1.0000 - val_loss: 20.4974 - val_accuracy: 0.2453 - lr: 1.3640e-05 - 26s/epoch - 3s/step\n",
            "Epoch 143/300\n",
            "10/10 - 26s - loss: 5.3969e-04 - accuracy: 1.0000 - val_loss: 18.9903 - val_accuracy: 0.2453 - lr: 1.3231e-05 - 26s/epoch - 3s/step\n",
            "Epoch 144/300\n",
            "10/10 - 24s - loss: 9.4350e-04 - accuracy: 1.0000 - val_loss: 60.6071 - val_accuracy: 0.5142 - lr: 1.2834e-05 - 24s/epoch - 2s/step\n",
            "Epoch 145/300\n",
            "10/10 - 25s - loss: 5.2832e-04 - accuracy: 1.0000 - val_loss: 181.1968 - val_accuracy: 0.2689 - lr: 1.2449e-05 - 25s/epoch - 2s/step\n",
            "Epoch 146/300\n",
            "10/10 - 26s - loss: 4.2094e-04 - accuracy: 1.0000 - val_loss: 223.3175 - val_accuracy: 0.2689 - lr: 1.2075e-05 - 26s/epoch - 3s/step\n",
            "Epoch 147/300\n",
            "10/10 - 26s - loss: 4.7392e-04 - accuracy: 1.0000 - val_loss: 254.7592 - val_accuracy: 0.2689 - lr: 1.1713e-05 - 26s/epoch - 3s/step\n",
            "Epoch 148/300\n",
            "10/10 - 24s - loss: 5.4800e-04 - accuracy: 1.0000 - val_loss: 293.6985 - val_accuracy: 0.2689 - lr: 1.1362e-05 - 24s/epoch - 2s/step\n",
            "Epoch 149/300\n",
            "10/10 - 25s - loss: 3.3602e-04 - accuracy: 1.0000 - val_loss: 287.1840 - val_accuracy: 0.2689 - lr: 1.1021e-05 - 25s/epoch - 2s/step\n",
            "Epoch 150/300\n",
            "10/10 - 25s - loss: 6.3169e-04 - accuracy: 1.0000 - val_loss: 268.2610 - val_accuracy: 0.2689 - lr: 1.0690e-05 - 25s/epoch - 2s/step\n",
            "Epoch 151/300\n",
            "10/10 - 23s - loss: 3.1551e-04 - accuracy: 1.0000 - val_loss: 228.0012 - val_accuracy: 0.2689 - lr: 1.0370e-05 - 23s/epoch - 2s/step\n",
            "Epoch 152/300\n",
            "10/10 - 25s - loss: 3.6692e-04 - accuracy: 1.0000 - val_loss: 173.2834 - val_accuracy: 0.2689 - lr: 1.0058e-05 - 25s/epoch - 2s/step\n",
            "Epoch 153/300\n",
            "10/10 - 27s - loss: 2.9945e-04 - accuracy: 1.0000 - val_loss: 141.5961 - val_accuracy: 0.2689 - lr: 9.7567e-06 - 27s/epoch - 3s/step\n",
            "Epoch 154/300\n",
            "10/10 - 23s - loss: 4.7084e-04 - accuracy: 1.0000 - val_loss: 138.6131 - val_accuracy: 0.2689 - lr: 9.4640e-06 - 23s/epoch - 2s/step\n",
            "Epoch 155/300\n",
            "10/10 - 25s - loss: 5.1684e-04 - accuracy: 1.0000 - val_loss: 188.4821 - val_accuracy: 0.2689 - lr: 9.1801e-06 - 25s/epoch - 2s/step\n",
            "Epoch 156/300\n",
            "10/10 - 25s - loss: 4.6125e-04 - accuracy: 1.0000 - val_loss: 200.3440 - val_accuracy: 0.2689 - lr: 8.9047e-06 - 25s/epoch - 2s/step\n",
            "Epoch 157/300\n",
            "10/10 - 25s - loss: 3.1244e-04 - accuracy: 1.0000 - val_loss: 176.5582 - val_accuracy: 0.2689 - lr: 8.6375e-06 - 25s/epoch - 2s/step\n",
            "Epoch 158/300\n",
            "10/10 - 25s - loss: 5.2648e-04 - accuracy: 1.0000 - val_loss: 158.1456 - val_accuracy: 0.2689 - lr: 8.3784e-06 - 25s/epoch - 2s/step\n",
            "Epoch 159/300\n",
            "10/10 - 26s - loss: 4.2561e-04 - accuracy: 1.0000 - val_loss: 165.2178 - val_accuracy: 0.2689 - lr: 8.1271e-06 - 26s/epoch - 3s/step\n",
            "Epoch 160/300\n",
            "10/10 - 25s - loss: 2.5471e-04 - accuracy: 1.0000 - val_loss: 167.7887 - val_accuracy: 0.2689 - lr: 7.8833e-06 - 25s/epoch - 2s/step\n",
            "Epoch 161/300\n",
            "10/10 - 24s - loss: 3.1416e-04 - accuracy: 1.0000 - val_loss: 164.7713 - val_accuracy: 0.2689 - lr: 7.6468e-06 - 24s/epoch - 2s/step\n",
            "Epoch 162/300\n",
            "10/10 - 26s - loss: 3.9267e-04 - accuracy: 1.0000 - val_loss: 136.3227 - val_accuracy: 0.2689 - lr: 7.4174e-06 - 26s/epoch - 3s/step\n",
            "Epoch 163/300\n",
            "10/10 - 25s - loss: 2.9766e-04 - accuracy: 1.0000 - val_loss: 137.1354 - val_accuracy: 0.2689 - lr: 7.1948e-06 - 25s/epoch - 3s/step\n",
            "Epoch 164/300\n",
            "10/10 - 26s - loss: 3.6227e-04 - accuracy: 1.0000 - val_loss: 159.8330 - val_accuracy: 0.2689 - lr: 6.9790e-06 - 26s/epoch - 3s/step\n",
            "Epoch 165/300\n",
            "10/10 - 24s - loss: 5.1566e-04 - accuracy: 1.0000 - val_loss: 150.3885 - val_accuracy: 0.2689 - lr: 6.7696e-06 - 24s/epoch - 2s/step\n",
            "Epoch 166/300\n",
            "10/10 - 25s - loss: 2.5094e-04 - accuracy: 1.0000 - val_loss: 129.6098 - val_accuracy: 0.2689 - lr: 6.5665e-06 - 25s/epoch - 2s/step\n",
            "Epoch 167/300\n",
            "10/10 - 26s - loss: 3.6696e-04 - accuracy: 1.0000 - val_loss: 116.8859 - val_accuracy: 0.2689 - lr: 6.3695e-06 - 26s/epoch - 3s/step\n",
            "Epoch 168/300\n",
            "10/10 - 26s - loss: 3.4812e-04 - accuracy: 1.0000 - val_loss: 104.0282 - val_accuracy: 0.2689 - lr: 6.1785e-06 - 26s/epoch - 3s/step\n",
            "Epoch 169/300\n",
            "10/10 - 24s - loss: 3.9746e-04 - accuracy: 1.0000 - val_loss: 83.8764 - val_accuracy: 0.5142 - lr: 5.9931e-06 - 24s/epoch - 2s/step\n",
            "Epoch 170/300\n",
            "10/10 - 25s - loss: 3.2810e-04 - accuracy: 1.0000 - val_loss: 61.3517 - val_accuracy: 0.5142 - lr: 5.8133e-06 - 25s/epoch - 2s/step\n",
            "Epoch 171/300\n",
            "10/10 - 26s - loss: 3.2359e-04 - accuracy: 1.0000 - val_loss: 52.8270 - val_accuracy: 0.5142 - lr: 5.6389e-06 - 26s/epoch - 3s/step\n",
            "Epoch 172/300\n",
            "10/10 - 24s - loss: 2.9053e-04 - accuracy: 1.0000 - val_loss: 45.6121 - val_accuracy: 0.5142 - lr: 5.4697e-06 - 24s/epoch - 2s/step\n",
            "Epoch 173/300\n",
            "10/10 - 25s - loss: 2.8302e-04 - accuracy: 1.0000 - val_loss: 37.5724 - val_accuracy: 0.5142 - lr: 5.3056e-06 - 25s/epoch - 2s/step\n",
            "Epoch 174/300\n",
            "10/10 - 26s - loss: 4.3666e-04 - accuracy: 1.0000 - val_loss: 27.9050 - val_accuracy: 0.5142 - lr: 5.1465e-06 - 26s/epoch - 3s/step\n",
            "Epoch 175/300\n",
            "10/10 - 25s - loss: 3.1829e-04 - accuracy: 1.0000 - val_loss: 19.4382 - val_accuracy: 0.5142 - lr: 4.9921e-06 - 25s/epoch - 2s/step\n",
            "Epoch 176/300\n",
            "10/10 - 24s - loss: 3.1776e-04 - accuracy: 1.0000 - val_loss: 25.5387 - val_accuracy: 0.5142 - lr: 4.8423e-06 - 24s/epoch - 2s/step\n",
            "Epoch 177/300\n",
            "10/10 - 26s - loss: 2.8244e-04 - accuracy: 1.0000 - val_loss: 27.9181 - val_accuracy: 0.5142 - lr: 4.6971e-06 - 26s/epoch - 3s/step\n",
            "Epoch 178/300\n",
            "10/10 - 26s - loss: 2.6878e-04 - accuracy: 1.0000 - val_loss: 19.1894 - val_accuracy: 0.5142 - lr: 4.5561e-06 - 26s/epoch - 3s/step\n",
            "Epoch 179/300\n",
            "10/10 - 26s - loss: 3.5289e-04 - accuracy: 1.0000 - val_loss: 10.2695 - val_accuracy: 0.5142 - lr: 4.4195e-06 - 26s/epoch - 3s/step\n",
            "Epoch 180/300\n",
            "10/10 - 24s - loss: 2.7498e-04 - accuracy: 1.0000 - val_loss: 5.0930 - val_accuracy: 0.5142 - lr: 4.2869e-06 - 24s/epoch - 2s/step\n",
            "Epoch 181/300\n",
            "10/10 - 25s - loss: 2.4553e-04 - accuracy: 1.0000 - val_loss: 1.6981 - val_accuracy: 0.7547 - lr: 4.1583e-06 - 25s/epoch - 3s/step\n",
            "Epoch 182/300\n",
            "10/10 - 25s - loss: 4.4573e-04 - accuracy: 1.0000 - val_loss: 14.2344 - val_accuracy: 0.5142 - lr: 4.0335e-06 - 25s/epoch - 3s/step\n",
            "Epoch 183/300\n",
            "10/10 - 24s - loss: 3.9166e-04 - accuracy: 1.0000 - val_loss: 18.5502 - val_accuracy: 0.5142 - lr: 3.9125e-06 - 24s/epoch - 2s/step\n",
            "Epoch 184/300\n",
            "10/10 - 25s - loss: 3.9927e-04 - accuracy: 1.0000 - val_loss: 18.0020 - val_accuracy: 0.5142 - lr: 3.7951e-06 - 25s/epoch - 2s/step\n",
            "Epoch 185/300\n",
            "10/10 - 25s - loss: 4.2037e-04 - accuracy: 1.0000 - val_loss: 15.8161 - val_accuracy: 0.5142 - lr: 3.6813e-06 - 25s/epoch - 3s/step\n",
            "Epoch 186/300\n",
            "10/10 - 26s - loss: 2.7163e-04 - accuracy: 1.0000 - val_loss: 9.9127 - val_accuracy: 0.5142 - lr: 3.5708e-06 - 26s/epoch - 3s/step\n",
            "Epoch 187/300\n",
            "10/10 - 24s - loss: 3.2971e-04 - accuracy: 1.0000 - val_loss: 10.7772 - val_accuracy: 0.5142 - lr: 3.4637e-06 - 24s/epoch - 2s/step\n",
            "Epoch 188/300\n",
            "10/10 - 26s - loss: 3.8483e-04 - accuracy: 1.0000 - val_loss: 1.7474 - val_accuracy: 0.7547 - lr: 3.3598e-06 - 26s/epoch - 3s/step\n",
            "Epoch 189/300\n",
            "10/10 - 25s - loss: 2.3712e-04 - accuracy: 1.0000 - val_loss: 1.9783 - val_accuracy: 0.4858 - lr: 3.2590e-06 - 25s/epoch - 3s/step\n",
            "Epoch 190/300\n",
            "10/10 - 27s - loss: 3.0729e-04 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9811 - lr: 3.1612e-06 - 27s/epoch - 3s/step\n",
            "Epoch 191/300\n",
            "10/10 - 24s - loss: 4.0533e-04 - accuracy: 1.0000 - val_loss: 9.4715e-05 - val_accuracy: 1.0000 - lr: 3.0664e-06 - 24s/epoch - 2s/step\n",
            "Epoch 192/300\n",
            "10/10 - 26s - loss: 2.7523e-04 - accuracy: 1.0000 - val_loss: 5.8355e-05 - val_accuracy: 1.0000 - lr: 2.9744e-06 - 26s/epoch - 3s/step\n",
            "Epoch 193/300\n",
            "10/10 - 26s - loss: 3.0717e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 2.8852e-06 - 26s/epoch - 3s/step\n",
            "Epoch 194/300\n",
            "10/10 - 27s - loss: 2.9689e-04 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9009 - lr: 2.7986e-06 - 27s/epoch - 3s/step\n",
            "Epoch 195/300\n",
            "10/10 - 24s - loss: 3.1135e-04 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9009 - lr: 2.7147e-06 - 24s/epoch - 2s/step\n",
            "Epoch 196/300\n",
            "10/10 - 25s - loss: 5.5373e-04 - accuracy: 1.0000 - val_loss: 12.8858 - val_accuracy: 0.5142 - lr: 2.6332e-06 - 25s/epoch - 2s/step\n",
            "Epoch 197/300\n",
            "10/10 - 25s - loss: 2.8887e-04 - accuracy: 1.0000 - val_loss: 21.5156 - val_accuracy: 0.5142 - lr: 2.5542e-06 - 25s/epoch - 3s/step\n",
            "Epoch 198/300\n",
            "10/10 - 26s - loss: 2.5489e-04 - accuracy: 1.0000 - val_loss: 21.0574 - val_accuracy: 0.5142 - lr: 2.4776e-06 - 26s/epoch - 3s/step\n",
            "Epoch 199/300\n",
            "10/10 - 23s - loss: 2.7968e-04 - accuracy: 1.0000 - val_loss: 13.3752 - val_accuracy: 0.5142 - lr: 2.4033e-06 - 23s/epoch - 2s/step\n",
            "Epoch 200/300\n",
            "10/10 - 26s - loss: 3.3287e-04 - accuracy: 1.0000 - val_loss: 9.3065 - val_accuracy: 0.5142 - lr: 2.3312e-06 - 26s/epoch - 3s/step\n",
            "Epoch 201/300\n",
            "10/10 - 25s - loss: 2.8703e-04 - accuracy: 1.0000 - val_loss: 8.7749 - val_accuracy: 0.5142 - lr: 2.2612e-06 - 25s/epoch - 2s/step\n",
            "Epoch 202/300\n",
            "10/10 - 24s - loss: 1.8590e-04 - accuracy: 1.0000 - val_loss: 4.6516 - val_accuracy: 0.5991 - lr: 2.1934e-06 - 24s/epoch - 2s/step\n",
            "Epoch 203/300\n",
            "10/10 - 25s - loss: 2.5695e-04 - accuracy: 1.0000 - val_loss: 3.9088 - val_accuracy: 0.5991 - lr: 2.1276e-06 - 25s/epoch - 2s/step\n",
            "Epoch 204/300\n",
            "10/10 - 25s - loss: 2.3576e-04 - accuracy: 1.0000 - val_loss: 2.7050 - val_accuracy: 0.7547 - lr: 2.0638e-06 - 25s/epoch - 3s/step\n",
            "Epoch 205/300\n",
            "10/10 - 26s - loss: 3.8654e-04 - accuracy: 1.0000 - val_loss: 4.5039 - val_accuracy: 0.5896 - lr: 2.0019e-06 - 26s/epoch - 3s/step\n",
            "Epoch 206/300\n",
            "10/10 - 24s - loss: 3.7315e-04 - accuracy: 1.0000 - val_loss: 8.7966 - val_accuracy: 0.5142 - lr: 1.9418e-06 - 24s/epoch - 2s/step\n",
            "Epoch 207/300\n",
            "10/10 - 26s - loss: 2.8053e-04 - accuracy: 1.0000 - val_loss: 8.4086 - val_accuracy: 0.5142 - lr: 1.8836e-06 - 26s/epoch - 3s/step\n",
            "Epoch 208/300\n",
            "10/10 - 25s - loss: 2.8738e-04 - accuracy: 1.0000 - val_loss: 5.8598 - val_accuracy: 0.5142 - lr: 1.8270e-06 - 25s/epoch - 3s/step\n",
            "Epoch 209/300\n",
            "10/10 - 27s - loss: 5.2051e-04 - accuracy: 1.0000 - val_loss: 3.3322 - val_accuracy: 0.5991 - lr: 1.7722e-06 - 27s/epoch - 3s/step\n",
            "Epoch 210/300\n",
            "10/10 - 23s - loss: 3.6267e-04 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.9009 - lr: 1.7191e-06 - 23s/epoch - 2s/step\n",
            "Epoch 211/300\n",
            "10/10 - 25s - loss: 3.0339e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000 - lr: 1.6675e-06 - 25s/epoch - 2s/step\n",
            "Epoch 212/300\n",
            "10/10 - 27s - loss: 3.2828e-04 - accuracy: 1.0000 - val_loss: 4.4552e-04 - val_accuracy: 1.0000 - lr: 1.6175e-06 - 27s/epoch - 3s/step\n",
            "Epoch 213/300\n",
            "10/10 - 25s - loss: 3.6769e-04 - accuracy: 1.0000 - val_loss: 1.0500 - val_accuracy: 0.4858 - lr: 1.5689e-06 - 25s/epoch - 2s/step\n",
            "Epoch 214/300\n",
            "10/10 - 25s - loss: 5.2516e-04 - accuracy: 1.0000 - val_loss: 3.3832 - val_accuracy: 0.4009 - lr: 1.5219e-06 - 25s/epoch - 2s/step\n",
            "Epoch 215/300\n",
            "10/10 - 25s - loss: 6.5552e-04 - accuracy: 1.0000 - val_loss: 2.6238 - val_accuracy: 0.4717 - lr: 1.4762e-06 - 25s/epoch - 3s/step\n",
            "Epoch 216/300\n",
            "10/10 - 27s - loss: 3.8812e-04 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000 - lr: 1.4319e-06 - 27s/epoch - 3s/step\n",
            "Epoch 217/300\n",
            "10/10 - 26s - loss: 2.9578e-04 - accuracy: 1.0000 - val_loss: 3.1124e-05 - val_accuracy: 1.0000 - lr: 1.3890e-06 - 26s/epoch - 3s/step\n",
            "Epoch 218/300\n",
            "10/10 - 23s - loss: 3.2160e-04 - accuracy: 1.0000 - val_loss: 2.6649e-05 - val_accuracy: 1.0000 - lr: 1.3473e-06 - 23s/epoch - 2s/step\n",
            "Epoch 219/300\n",
            "10/10 - 24s - loss: 2.8266e-04 - accuracy: 1.0000 - val_loss: 5.0370e-05 - val_accuracy: 1.0000 - lr: 1.3069e-06 - 24s/epoch - 2s/step\n",
            "Epoch 220/300\n",
            "10/10 - 25s - loss: 3.8163e-04 - accuracy: 1.0000 - val_loss: 6.6481e-04 - val_accuracy: 1.0000 - lr: 1.2677e-06 - 25s/epoch - 3s/step\n",
            "Epoch 221/300\n",
            "10/10 - 22s - loss: 3.1502e-04 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000 - lr: 1.2297e-06 - 22s/epoch - 2s/step\n",
            "Epoch 222/300\n",
            "10/10 - 25s - loss: 3.3829e-04 - accuracy: 1.0000 - val_loss: 5.1647e-04 - val_accuracy: 1.0000 - lr: 1.1928e-06 - 25s/epoch - 2s/step\n",
            "Epoch 223/300\n",
            "10/10 - 25s - loss: 5.1555e-04 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9575 - lr: 1.1570e-06 - 25s/epoch - 3s/step\n",
            "Epoch 224/300\n",
            "10/10 - 22s - loss: 3.3681e-04 - accuracy: 1.0000 - val_loss: 5.5028e-04 - val_accuracy: 1.0000 - lr: 1.1223e-06 - 22s/epoch - 2s/step\n",
            "Epoch 225/300\n",
            "10/10 - 24s - loss: 5.0184e-04 - accuracy: 1.0000 - val_loss: 1.5912e-04 - val_accuracy: 1.0000 - lr: 1.0886e-06 - 24s/epoch - 2s/step\n",
            "Epoch 226/300\n",
            "10/10 - 23s - loss: 2.5690e-04 - accuracy: 1.0000 - val_loss: 3.8458e-05 - val_accuracy: 1.0000 - lr: 1.0559e-06 - 23s/epoch - 2s/step\n",
            "Epoch 227/300\n",
            "10/10 - 23s - loss: 5.5462e-04 - accuracy: 1.0000 - val_loss: 1.2843e-04 - val_accuracy: 1.0000 - lr: 1.0243e-06 - 23s/epoch - 2s/step\n",
            "Epoch 228/300\n",
            "10/10 - 24s - loss: 3.1191e-04 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9009 - lr: 9.9354e-07 - 24s/epoch - 2s/step\n",
            "Epoch 229/300\n",
            "10/10 - 23s - loss: 2.6351e-04 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.9009 - lr: 9.6373e-07 - 23s/epoch - 2s/step\n",
            "Epoch 230/300\n",
            "10/10 - 24s - loss: 3.2965e-04 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9009 - lr: 9.3482e-07 - 24s/epoch - 2s/step\n",
            "Epoch 231/300\n",
            "10/10 - 24s - loss: 6.8648e-04 - accuracy: 1.0000 - val_loss: 5.7408 - val_accuracy: 0.4009 - lr: 9.0677e-07 - 24s/epoch - 2s/step\n",
            "Epoch 232/300\n",
            "10/10 - 22s - loss: 3.0657e-04 - accuracy: 1.0000 - val_loss: 7.9380 - val_accuracy: 0.4009 - lr: 8.7957e-07 - 22s/epoch - 2s/step\n",
            "Epoch 233/300\n",
            "10/10 - 25s - loss: 3.2697e-04 - accuracy: 1.0000 - val_loss: 8.8935 - val_accuracy: 0.4009 - lr: 8.5318e-07 - 25s/epoch - 2s/step\n",
            "Epoch 234/300\n",
            "10/10 - 24s - loss: 4.0494e-04 - accuracy: 1.0000 - val_loss: 8.7619 - val_accuracy: 0.4009 - lr: 8.2759e-07 - 24s/epoch - 2s/step\n",
            "Epoch 235/300\n",
            "10/10 - 23s - loss: 5.5961e-04 - accuracy: 1.0000 - val_loss: 7.6172 - val_accuracy: 0.4009 - lr: 8.0276e-07 - 23s/epoch - 2s/step\n",
            "Epoch 236/300\n",
            "10/10 - 24s - loss: 2.7062e-04 - accuracy: 1.0000 - val_loss: 6.4909 - val_accuracy: 0.4009 - lr: 7.7868e-07 - 24s/epoch - 2s/step\n",
            "Epoch 237/300\n",
            "10/10 - 25s - loss: 8.0383e-04 - accuracy: 1.0000 - val_loss: 6.8592 - val_accuracy: 0.4009 - lr: 7.5532e-07 - 25s/epoch - 3s/step\n",
            "Epoch 238/300\n",
            "10/10 - 22s - loss: 3.0328e-04 - accuracy: 1.0000 - val_loss: 7.4678 - val_accuracy: 0.4009 - lr: 7.3266e-07 - 22s/epoch - 2s/step\n",
            "Epoch 239/300\n",
            "10/10 - 25s - loss: 2.3575e-04 - accuracy: 1.0000 - val_loss: 7.1886 - val_accuracy: 0.4009 - lr: 7.1068e-07 - 25s/epoch - 2s/step\n",
            "Epoch 240/300\n",
            "10/10 - 24s - loss: 4.6003e-04 - accuracy: 1.0000 - val_loss: 7.2297 - val_accuracy: 0.4009 - lr: 6.8936e-07 - 24s/epoch - 2s/step\n",
            "Epoch 241/300\n",
            "10/10 - 23s - loss: 8.6637e-04 - accuracy: 1.0000 - val_loss: 7.9732 - val_accuracy: 0.4009 - lr: 6.6868e-07 - 23s/epoch - 2s/step\n",
            "Epoch 242/300\n",
            "10/10 - 24s - loss: 3.4446e-04 - accuracy: 1.0000 - val_loss: 9.1792 - val_accuracy: 0.4009 - lr: 6.4862e-07 - 24s/epoch - 2s/step\n",
            "Epoch 243/300\n",
            "10/10 - 27s - loss: 3.2738e-04 - accuracy: 1.0000 - val_loss: 9.1568 - val_accuracy: 0.4009 - lr: 6.2916e-07 - 27s/epoch - 3s/step\n",
            "Epoch 244/300\n",
            "10/10 - 24s - loss: 5.3006e-04 - accuracy: 1.0000 - val_loss: 8.8997 - val_accuracy: 0.4009 - lr: 6.1028e-07 - 24s/epoch - 2s/step\n",
            "Epoch 245/300\n",
            "10/10 - 26s - loss: 2.7931e-04 - accuracy: 1.0000 - val_loss: 8.5957 - val_accuracy: 0.4009 - lr: 5.9197e-07 - 26s/epoch - 3s/step\n",
            "Epoch 246/300\n",
            "10/10 - 26s - loss: 5.3860e-04 - accuracy: 1.0000 - val_loss: 8.2096 - val_accuracy: 0.4009 - lr: 5.7422e-07 - 26s/epoch - 3s/step\n",
            "Epoch 247/300\n",
            "10/10 - 27s - loss: 3.5119e-04 - accuracy: 1.0000 - val_loss: 8.2973 - val_accuracy: 0.4009 - lr: 5.5699e-07 - 27s/epoch - 3s/step\n",
            "Epoch 248/300\n",
            "10/10 - 24s - loss: 3.9390e-04 - accuracy: 1.0000 - val_loss: 8.0280 - val_accuracy: 0.4009 - lr: 5.4028e-07 - 24s/epoch - 2s/step\n",
            "Epoch 249/300\n",
            "10/10 - 25s - loss: 4.2772e-04 - accuracy: 1.0000 - val_loss: 7.5283 - val_accuracy: 0.4009 - lr: 5.2407e-07 - 25s/epoch - 3s/step\n",
            "Epoch 250/300\n",
            "10/10 - 25s - loss: 3.9868e-04 - accuracy: 1.0000 - val_loss: 7.7585 - val_accuracy: 0.4009 - lr: 5.0835e-07 - 25s/epoch - 3s/step\n",
            "Epoch 251/300\n",
            "10/10 - 25s - loss: 4.0772e-04 - accuracy: 1.0000 - val_loss: 7.5327 - val_accuracy: 0.4009 - lr: 4.9310e-07 - 25s/epoch - 3s/step\n",
            "Epoch 252/300\n",
            "10/10 - 24s - loss: 4.2954e-04 - accuracy: 1.0000 - val_loss: 6.6589 - val_accuracy: 0.4009 - lr: 4.7831e-07 - 24s/epoch - 2s/step\n",
            "Epoch 253/300\n",
            "10/10 - 26s - loss: 3.5472e-04 - accuracy: 1.0000 - val_loss: 5.4131 - val_accuracy: 0.4009 - lr: 4.6396e-07 - 26s/epoch - 3s/step\n",
            "Epoch 254/300\n",
            "10/10 - 26s - loss: 3.9048e-04 - accuracy: 1.0000 - val_loss: 5.0804 - val_accuracy: 0.4009 - lr: 4.5004e-07 - 26s/epoch - 3s/step\n",
            "Epoch 255/300\n",
            "10/10 - 26s - loss: 6.3084e-04 - accuracy: 1.0000 - val_loss: 4.4899 - val_accuracy: 0.4009 - lr: 4.3654e-07 - 26s/epoch - 3s/step\n",
            "Epoch 256/300\n",
            "10/10 - 24s - loss: 4.6133e-04 - accuracy: 1.0000 - val_loss: 1.1227 - val_accuracy: 0.4858 - lr: 4.2344e-07 - 24s/epoch - 2s/step\n",
            "Epoch 257/300\n",
            "10/10 - 26s - loss: 3.8047e-04 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000 - lr: 4.1074e-07 - 26s/epoch - 3s/step\n",
            "Epoch 258/300\n",
            "10/10 - 26s - loss: 2.8148e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000 - lr: 3.9842e-07 - 26s/epoch - 3s/step\n",
            "Epoch 259/300\n",
            "10/10 - 26s - loss: 4.1288e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - lr: 3.8646e-07 - 26s/epoch - 3s/step\n",
            "Epoch 260/300\n",
            "10/10 - 24s - loss: 5.8213e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 1.0000 - lr: 3.7487e-07 - 24s/epoch - 2s/step\n",
            "Epoch 261/300\n",
            "10/10 - 25s - loss: 5.4466e-04 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000 - lr: 3.6362e-07 - 25s/epoch - 2s/step\n",
            "Epoch 262/300\n",
            "10/10 - 25s - loss: 8.7425e-04 - accuracy: 1.0000 - val_loss: 2.2651e-04 - val_accuracy: 1.0000 - lr: 3.5271e-07 - 25s/epoch - 3s/step\n",
            "Epoch 263/300\n",
            "10/10 - 26s - loss: 7.0079e-04 - accuracy: 1.0000 - val_loss: 2.5059e-05 - val_accuracy: 1.0000 - lr: 3.4213e-07 - 26s/epoch - 3s/step\n",
            "Epoch 264/300\n",
            "10/10 - 23s - loss: 3.8660e-04 - accuracy: 1.0000 - val_loss: 2.5472e-05 - val_accuracy: 1.0000 - lr: 3.3187e-07 - 23s/epoch - 2s/step\n",
            "Epoch 265/300\n",
            "10/10 - 25s - loss: 4.2717e-04 - accuracy: 1.0000 - val_loss: 3.4814e-04 - val_accuracy: 1.0000 - lr: 3.2191e-07 - 25s/epoch - 2s/step\n",
            "Epoch 266/300\n",
            "10/10 - 24s - loss: 3.9553e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000 - lr: 3.1226e-07 - 24s/epoch - 2s/step\n",
            "Epoch 267/300\n",
            "10/10 - 23s - loss: 2.6396e-04 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 1.0000 - lr: 3.0289e-07 - 23s/epoch - 2s/step\n",
            "Epoch 268/300\n",
            "10/10 - 25s - loss: 2.8919e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 1.0000 - lr: 2.9380e-07 - 25s/epoch - 2s/step\n",
            "Epoch 269/300\n",
            "10/10 - 27s - loss: 2.9268e-04 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000 - lr: 2.8499e-07 - 27s/epoch - 3s/step\n",
            "Epoch 270/300\n",
            "10/10 - 23s - loss: 3.1937e-04 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 1.0000 - lr: 2.7644e-07 - 23s/epoch - 2s/step\n",
            "Epoch 271/300\n",
            "10/10 - 24s - loss: 3.3520e-04 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000 - lr: 2.6814e-07 - 24s/epoch - 2s/step\n",
            "Epoch 272/300\n",
            "10/10 - 25s - loss: 4.1247e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - lr: 2.6010e-07 - 25s/epoch - 3s/step\n",
            "Epoch 273/300\n",
            "10/10 - 26s - loss: 3.3642e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000 - lr: 2.5230e-07 - 26s/epoch - 3s/step\n",
            "Epoch 274/300\n",
            "10/10 - 23s - loss: 7.2690e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000 - lr: 2.4473e-07 - 23s/epoch - 2s/step\n",
            "Epoch 275/300\n",
            "10/10 - 25s - loss: 3.9621e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000 - lr: 2.3739e-07 - 25s/epoch - 3s/step\n",
            "Epoch 276/300\n",
            "10/10 - 24s - loss: 4.1244e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000 - lr: 2.3026e-07 - 24s/epoch - 2s/step\n",
            "Epoch 277/300\n",
            "10/10 - 23s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000 - lr: 2.2336e-07 - 23s/epoch - 2s/step\n",
            "Epoch 278/300\n",
            "10/10 - 25s - loss: 5.1806e-04 - accuracy: 1.0000 - val_loss: 1.0045 - val_accuracy: 0.4858 - lr: 2.1666e-07 - 25s/epoch - 3s/step\n",
            "Epoch 279/300\n",
            "10/10 - 25s - loss: 5.5764e-04 - accuracy: 1.0000 - val_loss: 1.3527 - val_accuracy: 0.4858 - lr: 2.1016e-07 - 25s/epoch - 2s/step\n",
            "Epoch 280/300\n",
            "10/10 - 23s - loss: 6.2498e-04 - accuracy: 1.0000 - val_loss: 1.7555 - val_accuracy: 0.4858 - lr: 2.0385e-07 - 23s/epoch - 2s/step\n",
            "Epoch 281/300\n",
            "10/10 - 24s - loss: 9.8520e-04 - accuracy: 1.0000 - val_loss: 1.2509 - val_accuracy: 0.4858 - lr: 1.9774e-07 - 24s/epoch - 2s/step\n",
            "Epoch 282/300\n",
            "10/10 - 25s - loss: 4.6210e-04 - accuracy: 1.0000 - val_loss: 0.5396 - val_accuracy: 0.5849 - lr: 1.9180e-07 - 25s/epoch - 3s/step\n",
            "Epoch 283/300\n",
            "10/10 - 23s - loss: 5.5070e-04 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 1.0000 - lr: 1.8605e-07 - 23s/epoch - 2s/step\n",
            "Epoch 284/300\n",
            "10/10 - 24s - loss: 3.3853e-04 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000 - lr: 1.8047e-07 - 24s/epoch - 2s/step\n",
            "Epoch 285/300\n",
            "10/10 - 24s - loss: 4.0453e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000 - lr: 1.7505e-07 - 24s/epoch - 2s/step\n",
            "Epoch 286/300\n",
            "10/10 - 23s - loss: 5.1470e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000 - lr: 1.6980e-07 - 23s/epoch - 2s/step\n",
            "Epoch 287/300\n",
            "10/10 - 25s - loss: 5.5809e-04 - accuracy: 1.0000 - val_loss: 3.5737e-04 - val_accuracy: 1.0000 - lr: 1.6471e-07 - 25s/epoch - 2s/step\n",
            "Epoch 288/300\n",
            "10/10 - 25s - loss: 4.0558e-04 - accuracy: 1.0000 - val_loss: 3.9570e-05 - val_accuracy: 1.0000 - lr: 1.5977e-07 - 25s/epoch - 2s/step\n",
            "Epoch 289/300\n",
            "10/10 - 23s - loss: 7.9503e-04 - accuracy: 1.0000 - val_loss: 7.9573e-05 - val_accuracy: 1.0000 - lr: 1.5497e-07 - 23s/epoch - 2s/step\n",
            "Epoch 290/300\n",
            "10/10 - 24s - loss: 5.4660e-04 - accuracy: 1.0000 - val_loss: 2.1729e-04 - val_accuracy: 1.0000 - lr: 1.5032e-07 - 24s/epoch - 2s/step\n",
            "Epoch 291/300\n",
            "10/10 - 25s - loss: 3.8486e-04 - accuracy: 1.0000 - val_loss: 3.9024e-04 - val_accuracy: 1.0000 - lr: 1.4582e-07 - 25s/epoch - 3s/step\n",
            "Epoch 292/300\n",
            "10/10 - 26s - loss: 6.1488e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000 - lr: 1.4144e-07 - 26s/epoch - 3s/step\n",
            "Epoch 293/300\n",
            "10/10 - 24s - loss: 5.3569e-04 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9009 - lr: 1.3720e-07 - 24s/epoch - 2s/step\n",
            "Epoch 294/300\n",
            "10/10 - 25s - loss: 5.0781e-04 - accuracy: 1.0000 - val_loss: 0.6396 - val_accuracy: 0.9009 - lr: 1.3308e-07 - 25s/epoch - 2s/step\n",
            "Epoch 295/300\n",
            "10/10 - 25s - loss: 9.0954e-04 - accuracy: 1.0000 - val_loss: 1.2235 - val_accuracy: 0.7547 - lr: 1.2909e-07 - 25s/epoch - 3s/step\n",
            "Epoch 296/300\n",
            "10/10 - 23s - loss: 6.8244e-04 - accuracy: 1.0000 - val_loss: 1.4887 - val_accuracy: 0.7547 - lr: 1.2522e-07 - 23s/epoch - 2s/step\n",
            "Epoch 297/300\n",
            "10/10 - 25s - loss: 4.7576e-04 - accuracy: 1.0000 - val_loss: 1.5170 - val_accuracy: 0.7547 - lr: 1.2146e-07 - 25s/epoch - 2s/step\n",
            "Epoch 298/300\n",
            "10/10 - 25s - loss: 5.8873e-04 - accuracy: 1.0000 - val_loss: 2.0786 - val_accuracy: 0.7547 - lr: 1.1782e-07 - 25s/epoch - 3s/step\n",
            "Epoch 299/300\n",
            "10/10 - 26s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5978 - val_accuracy: 0.7547 - lr: 1.1428e-07 - 26s/epoch - 3s/step\n",
            "Epoch 300/300\n",
            "10/10 - 23s - loss: 5.9495e-04 - accuracy: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.9009 - lr: 1.1085e-07 - 23s/epoch - 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = stft_model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "1sQqMIzvZm0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb90406d-de1e-4f51-acfd-157670072338"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9313187003135681\n"
          ]
        }
      ]
    }
  ]
}